{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fb1ae-b7bc-4c75-898a-8fd263a8c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure Python can import from reservoirs/ and utils/ etc. when running the notebook from notebooks/\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # go up one directory to parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d3a67-fa63-4f92-ab78-8eabb21eb53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard scientific libraries ---\n",
    "import itertools, tqdm, warnings, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D  # for 3D plotting\n",
    "from pathlib import Path\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.spatial import cKDTree, distance\n",
    "from numpy.linalg import norm\n",
    "from scipy.signal import hilbert, find_peaks \n",
    "from sklearn.linear_model import Ridge\n",
    "import inspect\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from scipy import signal\n",
    "from pathlib import Path\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# --- Reservoir implementations ---\n",
    "from reservoirs.cycle import CycleReservoir3D, CRJRes3D\n",
    "from reservoirs.sparse import SparseESN3D\n",
    "#from reservoirs.mci_esn import MCI3D\n",
    "#from reservoirs.parallel_esn import ParallelESN\n",
    "from reservoirs.deep_esn import DeepESN3D\n",
    "from reservoirs.small_world import SWRes3D_IO\n",
    "#from reservoirs.hyper import HyperbolicRes, EuclideanRes, SphericalRes\n",
    "#from reservoirs.hfr import HFR3D\n",
    "#from reservoirs.bei_stp import BEISTPReservoirESN\n",
    "#from reservoirs.swirl_gated_multicycle import SwirlGatedMultiCycleESN\n",
    "#from reservoirs.resonator import ResonatorReservoirESN\n",
    "#from reservoirs.glia_neuron import GliaNeuronTripartiteReservoirESN\n",
    "#from reservoirs.diffusion_wavelet import DiffusionWaveletReservoirESN, adj\n",
    "#from reservoirs.short_term_plasticity import STPESN\n",
    "#from reservoirs.ltsr import LTSRRes3D\n",
    "#from reservoirs.tgc import TGCCoupledESN\n",
    "from reservoirs.chord_esn import CHORDESN\n",
    "\n",
    "# --- Utility modules ---\n",
    "from utils.datasets import generate_lorenz_data, generate_rossler_data, generate_chen_data, generate_chua_data, generate_mackey_glass_data\n",
    "from utils.metrics import compute_valid_prediction_time, compute_attractor_deviation, evaluate_nrmse, mse_dimwise\n",
    "from utils.plotting import plot_timeseries, plot_lorenz_3d\n",
    "from utils.dynamics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bfe63-7fdc-4d4a-ae6b-da67bff19b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "from pathlib import Path\n",
    "\n",
    "FIG_DIR = Path(\"..\") / \"figures\"\n",
    "FIG_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc4a7c-9d22-498c-9947-943235f140f9",
   "metadata": {},
   "source": [
    "# Unified experiment driver for cannonical chaotic benchmarks with one knob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264075de-4245-4b41-8485-0a6f0524040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Unified driver with system-specific lambda_max\n",
    "# ============================================\n",
    "\n",
    "\n",
    "# -------- ONE KNOB for the chaotic system --------\n",
    "SYSTEM = \"chen-ueta\"            # 'lorenz' | 'rossler' | 'chen-ueta'\n",
    "DT      = 0.02\n",
    "TMAX    = 250.0\n",
    "WASHOUT = 2000\n",
    "\n",
    "# -------- Per-system generator params --------\n",
    "SYS_PARAMS = {\n",
    "    \"lorenz\":   dict(sigma=10.0, rho=28.0, beta=8.0/3.0),\n",
    "    \"rossler\":  dict(a=0.2, b=0.2, c=5.7),\n",
    "    \"chen-ueta\":dict(a=35.0, b=3.0, c=28.0),   \n",
    "}\n",
    "\n",
    "# Map system -> generator \n",
    "def _system_call(system: str, init_state, tmax=TMAX, dt=DT):\n",
    "    if system == \"lorenz\":\n",
    "        return generate_lorenz_data(initial_state=init_state, tmax=tmax, dt=dt, **SYS_PARAMS[\"lorenz\"])\n",
    "    elif system == \"rossler\":\n",
    "        return generate_rossler_data(initial_state=init_state, tmax=tmax, dt=dt, **SYS_PARAMS[\"rossler\"])\n",
    "    elif system in (\"chen\", \"chen-ueta\", \"chen_ueta\"):\n",
    "        return generate_chen_data(initial_state=init_state, tmax=tmax, dt=dt, **SYS_PARAMS[\"chen-ueta\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown SYSTEM={system}\")\n",
    "\n",
    "# -------- lambda_max configuration --------\n",
    "LAMBDA_MODE = \"auto\"   # \"auto\" (estimate from test data) or \"fixed\"\n",
    "LAMBDA_MAP  = {\n",
    "    \"lorenz\":    0.90,    # reference values \n",
    "    \"rossler\":   0.07,\n",
    "    \"chen-ueta\": 2.038,\n",
    "}\n",
    "\n",
    "def _estimate_lambda_rosenstein(traj: np.ndarray, dt: float,\n",
    "                                theiler: int = 50,\n",
    "                                max_horizon: int = 200,\n",
    "                                n_samples: int = 1500,\n",
    "                                fit_range: tuple[int,int] = (5, 60)) -> float:\n",
    "    \"\"\"\n",
    "    Rosenstein-style estimate of the largest Lyapunov exponent λ_max from a 3D trajectory.\n",
    "    Returns λ_max (1/time). Robust enough for medium T; falls back to map if unstable.\n",
    "    \"\"\"\n",
    "    X = np.asarray(traj, dtype=float)\n",
    "    T, d = X.shape\n",
    "    if d < 2 or T < theiler + max_horizon + 5:\n",
    "        return np.nan\n",
    "\n",
    "    # pick sample indices to form pairs\n",
    "    idx_pool = np.arange(0, T - max_horizon - 1)\n",
    "    if len(idx_pool) > n_samples:\n",
    "        rng = np.random.default_rng(0)\n",
    "        idx_pool = rng.choice(idx_pool, size=n_samples, replace=False)\n",
    "    idx_pool.sort()\n",
    "\n",
    "    # nearest neighbor search with Theiler window exclusion\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm=\"auto\").fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "    nn = np.empty_like(indices[:, 1])\n",
    "    for i in range(T):\n",
    "        # default: nearest neighbor index (excluding self is usually at slot 1)\n",
    "        j = indices[i, 1]\n",
    "        # if within Theiler, search further neighbors\n",
    "        k = 2\n",
    "        while abs(j - i) <= theiler and k < indices.shape[1]:\n",
    "            j = indices[i, k]; k += 1\n",
    "        # if all within Theiler (unlikely), skip by marking invalid\n",
    "        nn[i] = j\n",
    "\n",
    "    # compute mean log divergence curve\n",
    "    taus = np.arange(1, max_horizon+1)\n",
    "    log_div = np.zeros_like(taus, dtype=float)\n",
    "    counts  = np.zeros_like(taus, dtype=int)\n",
    "\n",
    "    eps = 1e-12\n",
    "    for i in idx_pool:\n",
    "        j = nn[i]\n",
    "        if abs(j - i) <= theiler:\n",
    "            continue\n",
    "        # advance both points together\n",
    "        max_tau = min(max_horizon, T-1-i, T-1-j)\n",
    "        if max_tau < 5:\n",
    "            continue\n",
    "        diffs = X[i+1:i+max_tau+1] - X[j+1:j+max_tau+1]\n",
    "        ds = np.linalg.norm(diffs, axis=1) + eps\n",
    "        log_div[:max_tau] += np.log(ds)\n",
    "        counts[:max_tau]  += 1\n",
    "\n",
    "    valid = counts > 0\n",
    "    if not np.any(valid):\n",
    "        return np.nan\n",
    "    mean_log_div = np.zeros_like(log_div)\n",
    "    mean_log_div[valid] = log_div[valid] / counts[valid]\n",
    "\n",
    "    # linear fit on a reasonable window\n",
    "    t0, t1 = fit_range\n",
    "    t0 = max(t0, 1)\n",
    "    t1 = min(t1, np.max(np.where(valid)[0], initial=t1))\n",
    "    if t1 - t0 < 5:\n",
    "        return np.nan\n",
    "    x = taus[t0:t1] * dt\n",
    "    y = mean_log_div[t0:t1]\n",
    "    slope, _ = np.polyfit(x, y, 1)\n",
    "    return float(max(slope, 0.0))  # λ ≥ 0\n",
    "\n",
    "def get_lambda_max(system: str, test_y: np.ndarray, dt: float) -> float:\n",
    "    \"\"\"Choose λ_max per LAMBDA_MODE.\"\"\"\n",
    "    if LAMBDA_MODE == \"fixed\":\n",
    "        return float(LAMBDA_MAP[system])\n",
    "    # auto\n",
    "    lam = _estimate_lambda_rosenstein(test_y, dt)\n",
    "    if not np.isfinite(lam) or lam <= 0:\n",
    "        lam = float(LAMBDA_MAP[system])\n",
    "    return lam\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Experiment grid\n",
    "# ----------------------------------------------------------------------------------\n",
    "init_grid  = [[1.0, 1.0, 1.0]]\n",
    "seed_grid  = list(range(1, 15))\n",
    "split_grid = [0.8]\n",
    "rho_grid   = [0.95]\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Model factories \n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "#########        For Lorenz and Chen-Ueta     ###########\n",
    "BASELINES = {\n",
    "    \"Cycle\" : lambda ρ, seed: CycleReservoir3D(\n",
    "        reservoir_size=400, spectral_radius=ρ,\n",
    "        input_scale=0.2, leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4, seed=seed),\n",
    "\n",
    "    \"ESN\": lambda ρ, seed: SparseESN3D(\n",
    "        reservoir_size=400, spectral_radius=ρ, connectivity=0.05,\n",
    "        input_scale=0.2, leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4, seed=seed),\n",
    "\n",
    "    \"CRJ\"   : lambda ρ, seed: CRJRes3D(\n",
    "        reservoir_size=400, edge_weight=0.8, jump=10,\n",
    "        spectral_radius=ρ, input_scale=0.2,\n",
    "        leaking_rate=0.2, ridge_alpha=1e-4, seed=seed),\n",
    "\n",
    "   \"SW\": lambda ρ, seed: SWRes3D_IO(\n",
    "    reservoir_size=400,\n",
    "    spectral_radius=0.99,\n",
    "    rewiring_prob=0.15,\n",
    "    degree=12,\n",
    "    gain=0.86,\n",
    "    input_scale=0.16,\n",
    "    leaking_rate=0.77,\n",
    "    ridge_alpha=3.0e-08,\n",
    "    num_input_nodes=23,\n",
    "    num_output_nodes=13,\n",
    "    io_separation_mode=\"random\",\n",
    "    seed=seed\n",
    "),\n",
    "\n",
    "    \"Deep\"  : lambda ρ, seed: DeepESN3D(\n",
    "        num_layers=3, reservoir_size=400,\n",
    "        spectral_radius=ρ, input_scale=0.2,\n",
    "        leaking_rate=0.2, input_dim=3,\n",
    "        ridge_alpha=1e-4, seed=seed),\n",
    "}\n",
    "\n",
    "######### For Rossler  ##########\n",
    "# BASELINES = {\n",
    "#     \"ESN\": lambda ρ, seed: SparseESN3D(\n",
    "#         reservoir_size=400,\n",
    "#         spectral_radius=ρ,\n",
    "#         connectivity=0.07,\n",
    "#         input_scale=0.05,\n",
    "#         leaking_rate=0.57,\n",
    "#         ridge_alpha=2.0e-07,\n",
    "#         seed=seed\n",
    "#     ),\n",
    "    \n",
    "#     \"Cycle\": lambda ρ, seed: CycleReservoir3D(\n",
    "#         reservoir_size=400,\n",
    "#         spectral_radius=ρ,\n",
    "#         input_scale=0.03,\n",
    "#         leaking_rate=0.80,\n",
    "#         ridge_alpha=2.5e-07,\n",
    "#         seed=seed\n",
    "#     ),\n",
    "    \n",
    "#     \"CRJ\": lambda ρ, seed: CRJRes3D(\n",
    "#         reservoir_size=400,\n",
    "#         spectral_radius=ρ,\n",
    "#         edge_weight=0.99,\n",
    "#         jump=6,\n",
    "#         input_scale=0.05,\n",
    "#         leaking_rate=0.61,\n",
    "#         ridge_alpha= 2.1e-08,\n",
    "#         seed=seed\n",
    "#     ),\n",
    "    \n",
    "#     \"SW\": lambda ρ, seed: SWRes3D_IO(\n",
    "#         reservoir_size=400,\n",
    "#         spectral_radius=ρ,\n",
    "#         rewiring_prob=0.15,\n",
    "#         degree=12,\n",
    "#         gain=0.86,\n",
    "#         input_scale=0.17,\n",
    "#         leaking_rate=0.77,\n",
    "#         ridge_alpha=3.0e-08,\n",
    "#         num_input_nodes=23,\n",
    "#         num_output_nodes=13,\n",
    "#         io_separation_mode=\"random\",\n",
    "#         seed=seed\n",
    "#     ),\n",
    "\n",
    "#     \"Deep\"  : lambda ρ, seed: DeepESN3D(\n",
    "#         num_layers=3, reservoir_size=400,\n",
    "#         spectral_radius=ρ, input_scale=0.2,\n",
    "#         leaking_rate=0.2, input_dim=3,\n",
    "#         ridge_alpha=1e-4, seed=seed),\n",
    "    \n",
    "# }\n",
    "\n",
    "TESTING_NAME      = \"CHORD-ESN\"\n",
    "TESTING_RES_CLASS = CHORDESN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### for lorenz  #####\n",
    "# def make_testing(ρ, seed):\n",
    "    # return TESTING_RES_CLASS(\n",
    "    #     num_nodes        = 400,\n",
    "    #     input_dim        = 3,\n",
    "    #     avg_degree       = 8,\n",
    "    #     lam_node         = 0.25,\n",
    "    #     lam_edge         = 0.25,\n",
    "    #     lam_face         = 0.25,\n",
    "    #     leak_exact       = 0.40,\n",
    "    #     leak_coexact     = 0.40,\n",
    "    #     leak_harm        = 0.06,\n",
    "    #     heat0            = 0.05,\n",
    "    #     heat1            = 0.05,\n",
    "    #     heat2            = 0.05,\n",
    "    #     alpha            = 0.30,\n",
    "    #     beta             = 0.30,\n",
    "    #     gamma            = 0.30,\n",
    "    #     node_mix_gain    = 0.30,\n",
    "    #     edge_mix_gain    = 0.30,\n",
    "    #     face_mix_gain    = 0.30,\n",
    "    #     input_scale_node = 0.50,\n",
    "    #     input_scale_edge = 0.50,\n",
    "    #     input_scale_face = 0.50,\n",
    "    #     projector_eps    = 1e-4,\n",
    "    #     cg_tol           = 1e-6,\n",
    "    #     cg_maxiter       = 200,\n",
    "    #     proj_every       = 5,\n",
    "    #     ridge_alpha      = 1e-6,\n",
    "    #     use_poly         = True,\n",
    "    #     feature_mode     = \"node_harm\",\n",
    "    #     seed              = seed,\n",
    "    # )\n",
    "\n",
    "########   for rossler    #######\n",
    "# def make_testing(ρ, seed):\n",
    "#     return TESTING_RES_CLASS(\n",
    "        # num_nodes        = 400,\n",
    "        # input_dim        = 3,\n",
    "        # avg_degree       = 11,\n",
    "        # lam_node         = 0.33,\n",
    "        # lam_edge         = 0.52,\n",
    "        # lam_face         = 0.45,\n",
    "        # leak_exact       = 0.20,\n",
    "        # leak_coexact     = 0.20,\n",
    "        # leak_harm        = 0.06,\n",
    "        # heat0            = 0.03,\n",
    "        # heat1            = 0.04,\n",
    "        # heat2            = 0.02,\n",
    "        # alpha            = 0.15,\n",
    "        # beta             = 0.36,\n",
    "        # gamma            = 0.49,\n",
    "        # node_mix_gain    = 0.76,\n",
    "        # edge_mix_gain    = 0.17,\n",
    "        # face_mix_gain    = 0.33,\n",
    "        # input_scale_node = 0.07,\n",
    "        # input_scale_edge = 0.18,\n",
    "        # input_scale_face = 0.08,\n",
    "        # projector_eps    = 0.000197,\n",
    "        # cg_tol           = 0.000006,\n",
    "        # cg_maxiter       = 125,\n",
    "        # proj_every       = 4,\n",
    "        # ridge_alpha      = 1e-4,\n",
    "        # use_poly         = False,\n",
    "        # feature_mode     = \"node_harm\",\n",
    "        # seed             = seed,\n",
    "#     )\n",
    "\n",
    "####for chen-ueta\n",
    "def make_testing(ρ, seed):\n",
    "    return TESTING_RES_CLASS(\n",
    "        num_nodes         = 400,\n",
    "        input_dim         = 3,\n",
    "        edges             = None,\n",
    "        faces             = None,\n",
    "        avg_degree        = 9,            \n",
    "        star0_diag        = None,\n",
    "        star1_diag        = None,\n",
    "        star2_diag        = None,\n",
    "        lam_node          = 0.35,          \n",
    "        lam_edge          = 0.33,         \n",
    "        lam_face          = 0.35,         \n",
    "        leak_exact        = 0.20,         \n",
    "        leak_coexact      = 0.20,         \n",
    "        leak_harm         = 0.06,          \n",
    "        heat0             = 0.06,          \n",
    "        heat1             = 0.01,          \n",
    "        heat2             = 0.02,          \n",
    "        alpha             = 0.41,          \n",
    "        beta              = 0.22,          \n",
    "        gamma             = 0.37,         \n",
    "        node_mix_gain     = 0.67,          \n",
    "        edge_mix_gain     = 0.45,         \n",
    "        face_mix_gain     = 0.44,          \n",
    "        input_scale_node  = 0.15,          \n",
    "        input_scale_edge  = 0.21,          \n",
    "        input_scale_face  = 0.12,         \n",
    "        projector_eps     = 0.000615,      \n",
    "        cg_tol            = 0.000624,     \n",
    "        cg_maxiter        = 100,           \n",
    "        proj_every        = 1,             \n",
    "        ridge_alpha       = 1e-6,      \n",
    "        use_poly          = True,          \n",
    "        feature_mode      = \"node_harm\",  \n",
    "        seed              = seed,\n",
    "    )\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# DATA cache: original test trajectory + its lambda_max (per scenario)\n",
    "# ----------------------------------------------------------------------------------\n",
    "DATA = {}\n",
    "for init_id, init_state in enumerate(init_grid, start=1):\n",
    "    t_vals, full_data = _system_call(SYSTEM, init_state, tmax=TMAX, dt=DT)\n",
    "    full_data = full_data[WASHOUT:]\n",
    "    for split in split_grid:\n",
    "        idx = int(split * (len(full_data) - 1))\n",
    "        train_in,  train_y  = full_data[:idx],  full_data[1:idx+1]\n",
    "        test_in,   test_y   = full_data[idx:-1], full_data[idx+1:]\n",
    "        time_test = np.arange(len(test_y)) * DT\n",
    "        # compute/choose lambda_max for THIS scenario's original test trajectory\n",
    "        lambda_max = get_lambda_max(SYSTEM, test_y, DT)\n",
    "        DATA[(init_id, split)] = dict(\n",
    "            train_in=train_in, train_y=train_y,\n",
    "            test_in=test_in,   test_y=test_y,\n",
    "            time_test=time_test,\n",
    "            lambda_max=lambda_max\n",
    "        )\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Runner uses scenario-specific lambda_max\n",
    "# ----------------------------------------------------------------------------------\n",
    "def run_one(model, ds):\n",
    "    model.fit_readout(ds[\"train_in\"], ds[\"train_y\"], discard=100)\n",
    "    preds = model.predict_autoregressive(ds[\"test_in\"][0], len(ds[\"test_y\"]))\n",
    "    horizons = [200, 500, 1000]\n",
    "    nrmse = evaluate_nrmse(preds, ds[\"test_y\"], horizons)[horizons[-1]]\n",
    "    T_VPT, T_lambda, ratio = compute_valid_prediction_time(\n",
    "        ds[\"test_y\"], preds, ds[\"time_test\"],\n",
    "        threshold=0.4, lambda_max=ds[\"lambda_max\"]\n",
    "    )\n",
    "    adev = compute_attractor_deviation(ds[\"test_y\"], preds, cube_size=(4,4,4))\n",
    "    return dict(NRMSE=nrmse, VPT=T_VPT, ADev=adev, preds=preds)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# Main sweep\n",
    "# ----------------------------------------------------------------------------------\n",
    "records, pred_store = [], {}\n",
    "for (init_id, split), ds in tqdm.tqdm(DATA.items(), desc=\"Scenarios\"):\n",
    "    for ρ in rho_grid:\n",
    "        for seed in seed_grid:\n",
    "            for name, factory in BASELINES.items():\n",
    "                out = run_one(factory(ρ, seed), ds)\n",
    "                key = (name, init_id, split, ρ, seed)\n",
    "                records.append((name, init_id, split, ρ, seed, out[\"NRMSE\"], out[\"VPT\"], out[\"ADev\"]))\n",
    "                pred_store[key] = out[\"preds\"]\n",
    "\n",
    "            out = run_one(make_testing(ρ, seed), ds)\n",
    "            key = (TESTING_NAME, init_id, split, ρ, seed)\n",
    "            records.append((TESTING_NAME, init_id, split, ρ, seed, out[\"NRMSE\"], out[\"VPT\"], out[\"ADev\"]))\n",
    "            pred_store[key] = out[\"preds\"]\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\"Model\", \"Init\", \"Split\", \"Rho\", \"Seed\", \"NRMSE\", \"VPT\", \"ADev\"])\n",
    "summary = (df.groupby([\"Model\", \"Split\", \"Rho\"])\n",
    "             .agg(NRMSE_mean=(\"NRMSE\",\"mean\"), NRMSE_sd=(\"NRMSE\",\"std\"),\n",
    "                  VPT_mean =(\"VPT\",\"mean\"),   VPT_sd =(\"VPT\",\"std\"),\n",
    "                  ADev_mean=(\"ADev\",\"mean\"),  ADev_sd=(\"ADev\",\"std\"))\n",
    "             .round(4))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceee7a4-c55f-4a00-be2e-848fd07fd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== OVERALL SUMMARY ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4029da6-7830-4581-aa52-83420af97d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# Horizon‑wise NRMSE table  (mean ± sd)  — horizons as rows\n",
    "# ----------------------------------------------------------------------------------\n",
    "horizons = [200, 400, 600, 800, 1000]\n",
    "rows = []\n",
    "for key, preds in pred_store.items():               # key=(Model,Init,Split,Rho,Seed)\n",
    "    model = key[0]\n",
    "    nrmse_vec = evaluate_nrmse(preds, test_y, horizons)\n",
    "    for h in horizons:\n",
    "        rows.append(dict(Model=model, Horizon=h, NRMSE=nrmse_vec[h]))\n",
    "\n",
    "df_h = pd.DataFrame(rows)\n",
    "tab = (df_h.groupby([\"Model\", \"Horizon\"])\n",
    "           .agg(mean=(\"NRMSE\",\"mean\"), sd=(\"NRMSE\",\"std\"))\n",
    "           .round(4))\n",
    "tab[\"NRMSE\"] = tab[\"mean\"].astype(str) + \" ± \" + tab[\"sd\"].astype(str)\n",
    "\n",
    "matrix = (tab[\"NRMSE\"]\n",
    "            .unstack(\"Model\")       # columns = models\n",
    "            .reindex(horizons)      # rows  = horizons\n",
    "            .rename_axis(\"Horizon\"))\n",
    "\n",
    "print(\"\\n=== NRMSE (mean ± sd)  —  horizons in rows ===\")\n",
    "print(matrix.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b27ada-0f3b-46c5-909e-328d950f45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# VPT & ADev  (mean ± sd)  — one row per model\n",
    "# ----------------------------------------------------------------------------------\n",
    "metric_table = (df.groupby(\"Model\")\n",
    "                  .agg(VPT_mean=(\"VPT\", \"mean\"),  VPT_sd=(\"VPT\", \"std\"),\n",
    "                       ADev_mean=(\"ADev\", \"mean\"), ADev_sd=(\"ADev\", \"std\"))\n",
    "                  .round(3))\n",
    "metric_table[\"VPT\"]  = metric_table[\"VPT_mean\"].astype(str)  + \" ± \" + metric_table[\"VPT_sd\"].astype(str)\n",
    "metric_table[\"ADev\"] = metric_table[\"ADev_mean\"].astype(str) + \" ± \" + metric_table[\"ADev_sd\"].astype(str)\n",
    "\n",
    "print(\"\\n===  VPT  &  ADev  (mean ± sd)  ===\")\n",
    "print(metric_table[[\"VPT\", \"ADev\"]].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b22fd-a3b8-4a66-aed3-9df8a07adef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "def build_nrmse_by_horizon_df(pred_store, DATA, horizons=(400,600,800,1000), exclude_models=None):\n",
    "    \"\"\"\n",
    "    Build NRMSE rows for given horizons. Optionally exclude models by name.\n",
    "    \"\"\"\n",
    "    exclude_models = set(exclude_models or [])\n",
    "    rows = []\n",
    "    for (model, init_id, split, rho, seed), preds in pred_store.items():\n",
    "        if model in exclude_models:\n",
    "            continue\n",
    "        test_y = DATA[(init_id, split)][\"test_y\"]     # ORIGINAL test target\n",
    "        nrmse = evaluate_nrmse(preds, test_y, list(horizons))\n",
    "        for h in horizons:\n",
    "            rows.append({\n",
    "                \"Model\": model, \"Horizon\": h, \"NRMSE\": nrmse[h],\n",
    "                \"Init\": init_id, \"Split\": split, \"Rho\": rho, \"Seed\": seed\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Build DF \n",
    "df_nrmse_h = build_nrmse_by_horizon_df(\n",
    "    pred_store, DATA, horizons=(400,600,800,1000), exclude_models={\"SW\"}\n",
    ")\n",
    "\n",
    "# Order + palette\n",
    "horizons = sorted(df_nrmse_h[\"Horizon\"].unique())\n",
    "models   = sorted(df_nrmse_h[\"Model\"].unique())\n",
    "pal      = sns.color_palette(\"tab10\", n_colors=len(models))\n",
    "color_of = {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "# ======= manual grouped boxplot with small separation =======\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "centers    = np.arange(len(horizons))             # one group per horizon\n",
    "group_width = 0.90                                 # total width reserved for the whole group\n",
    "inner_gap   = 0.03                                 # small gap between adjacent boxes\n",
    "M           = len(models)\n",
    "box_w       = (group_width - inner_gap*(M-1)) / max(M, 1)  # width of each box\n",
    "offsets     = np.linspace(-(group_width/2) + box_w/2,\n",
    "                          +(group_width/2) - box_w/2, M)\n",
    "\n",
    "# Collect data & positions\n",
    "all_data, positions, colors = [], [], []\n",
    "for gi, h in enumerate(horizons):\n",
    "    center = centers[gi]\n",
    "    for mi, m in enumerate(models):\n",
    "        vals = df_nrmse_h.query(\"Horizon == @h and Model == @m\")[\"NRMSE\"].values\n",
    "        all_data.append(vals)\n",
    "        positions.append(center + offsets[mi])\n",
    "        colors.append(color_of[m])\n",
    "\n",
    "bp = ax.boxplot(\n",
    "    all_data, positions=positions, widths=box_w*0.95,\n",
    "    patch_artist=True, showcaps=True, showfliers=False,\n",
    "    medianprops=dict(color=\"#222\", linewidth=1.6),\n",
    "    whiskerprops=dict(color=\"#555\", linewidth=1.2),\n",
    "    capprops=dict(color=\"#555\", linewidth=1.2)\n",
    ")\n",
    "\n",
    "# Color boxes\n",
    "for patch, c in zip(bp[\"boxes\"], colors):\n",
    "    patch.set_facecolor(c)\n",
    "    patch.set_edgecolor(\"#333\")\n",
    "    patch.set_alpha(0.75)\n",
    "    patch.set_linewidth(1.0)\n",
    "\n",
    "# X ticks at group centers\n",
    "ax.set_xticks(centers)\n",
    "ax.set_xticklabels([str(h) for h in horizons])\n",
    "\n",
    "# Legend\n",
    "handles = [Patch(facecolor=color_of[m], edgecolor=\"#333\", label=m, alpha=0.75) for m in models]\n",
    "ax.legend(handles=handles, title=\"Model\", ncol=3, frameon=False)\n",
    "\n",
    "#ax.set_title(f\"{SYSTEM.title()}: NRMSE distribution by horizon\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"NRMSE\")\n",
    "ax.grid(axis=\"y\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / f\"{SYSTEM}_box_nrmse_by_horizon.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b98841-e10e-4c37-9313-9150de1822b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlays_separate(pred_store, DATA, init_id, split, rho, seed,\n",
    "                           palette=None, truth_color=\"#444444\",\n",
    "                           max_len=1500, dpi=300):\n",
    "    \"\"\"\n",
    "    One figure per model: 3 stacked panels (x,y,z),\n",
    "    model trajectory vs ORIGINAL ground truth (dotted).\n",
    "    Uses DATA[(init_id, split)] to avoid recomputation.\n",
    "    \"\"\"\n",
    "    # --- fetch original test trajectory from cache ---\n",
    "    key_ds = (init_id, split)\n",
    "    if key_ds not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init_id={init_id}, split={split}).\")\n",
    "    time_test = DATA[key_ds][\"time_test\"]\n",
    "    test_y    = DATA[key_ds][\"test_y\"]\n",
    "\n",
    "    # truncation for display\n",
    "    Ttruth = len(time_test)\n",
    "    if max_len is not None:\n",
    "        Ttruth   = min(Ttruth, max_len)\n",
    "        time_plot = time_test[:Ttruth]\n",
    "        y_plot    = test_y[:Ttruth]\n",
    "    else:\n",
    "        time_plot = time_test\n",
    "        y_plot    = test_y\n",
    "\n",
    "    # which models actually exist for this exact scenario?\n",
    "    scenario_models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    if not scenario_models:\n",
    "        raise ValueError(f\"No predictions found for (init={init_id}, split={split}, ρ={rho}, seed={seed}).\")\n",
    "\n",
    "    # palette\n",
    "    if palette is None:\n",
    "        # build a stable palette just for the models in this scenario\n",
    "        base = sns.color_palette(\"tab10\", n_colors=max(10, len(scenario_models)))\n",
    "        palette = {name: base[idx % len(base)] for idx, name in enumerate(scenario_models)}\n",
    "\n",
    "    dim_names = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "\n",
    "    for model in scenario_models:\n",
    "        preds = pred_store[(model, init_id, split, rho, seed)]\n",
    "        T = min(Ttruth, preds.shape[0])\n",
    "        preds = preds[:T]\n",
    "\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(11, 8), sharex=True)\n",
    "        for d, ax in enumerate(axes):\n",
    "            # ground truth (dotted)\n",
    "            ax.plot(time_plot[:T], y_plot[:T, d],\n",
    "                    linestyle=\":\", lw=1.8, color=truth_color, label=\"Ground truth\")\n",
    "            # model\n",
    "            ax.plot(time_plot[:T], preds[:, d],\n",
    "                    lw=1.4, color=palette[model], label=model)\n",
    "            ax.set_ylabel(dim_names[d])\n",
    "            ax.grid(alpha=0.25)\n",
    "            if d == 0:\n",
    "                ax.legend(frameon=False, ncol=2)\n",
    "\n",
    "        axes[-1].set_xlabel(\"Time\")\n",
    "        #plt.suptitle(f\"{SYSTEM}{model} vs Ground Truth  |  init={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "        out = FIG_DIR / f\"{SYSTEM}-overlay_{model}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "        plt.savefig(out, dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        print(f\"Saved: {out}\")\n",
    "\n",
    "plot_overlays_separate(\n",
    "    pred_store, DATA,\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    truth_color=\"#3b3b3b\", max_len=2000, dpi=300\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b936bf-8428-4100-ba05-c3cb87cc6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- deps ---\n",
    "\n",
    "DIM_LABELS = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "TRUTH_COLOR = \"#3b3b3b\"   # dotted charcoal for truth\n",
    "\n",
    "def make_model_palette(pred_store, palette_name=\"colorblind\"):\n",
    "    models = sorted({k[0] for k in pred_store.keys()})\n",
    "    pal = sns.color_palette(palette_name, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "def make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name=\"colorblind\"):\n",
    "    models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    pal = sns.color_palette(palette_name, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "PALETTE = make_model_palette(pred_store)  # global fallback\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# PSD — SEPARATE FIGURES for ALL MODELS (choose one component x/y/z)\n",
    "# -----------------------------------------------------------------------------\n",
    "def plot_psd_all_models_separate(pred_store, DATA, init_id, split, rho, seed,\n",
    "                                 dim=0, max_len=None, nperseg=1024, noverlap=None,\n",
    "                                 window=\"hann\", detrend=\"constant\", scaling=\"density\",\n",
    "                                 palette_name=\"colorblind\",\n",
    "                                 truth_color=TRUTH_COLOR, dpi=300):\n",
    "    \"\"\"\n",
    "    For the given scenario (init_id, split, rho, seed), make one PSD figure per model\n",
    "    on a single chosen component dim ∈ {0,1,2} (x/y/z), vs the ORIGINAL ground truth.\n",
    "    \"\"\"\n",
    "    if dim not in (0, 1, 2):\n",
    "        raise ValueError(\"dim must be 0 (x), 1 (y), or 2 (z).\")\n",
    "\n",
    "    # --- fetch truth & fs from cache ---\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init_id={init_id}, split={split}).\")\n",
    "\n",
    "    t       = DATA[ds_key][\"time_test\"]\n",
    "    y_true  = DATA[ds_key][\"test_y\"]\n",
    "    fs      = 1.0 / np.mean(np.diff(t))\n",
    "    T       = len(t) if max_len is None else min(len(t), max_len)\n",
    "    y_true  = y_true[:T]\n",
    "\n",
    "    # models available for this exact scenario\n",
    "    scenario_models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    if not scenario_models:\n",
    "        raise ValueError(f\"No predictions for (init={init_id}, split={split}, ρ={rho}, seed={seed}).\")\n",
    "\n",
    "    palette = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "\n",
    "    # compute truth PSD once for the chosen component\n",
    "    nperseg_eff = max(16, min(nperseg, T))\n",
    "    f_t, P_t = signal.welch(y_true[:, dim], fs=fs, window=window,\n",
    "                            nperseg=nperseg_eff, noverlap=noverlap,\n",
    "                            detrend=detrend, scaling=scaling, return_onesided=True)\n",
    "\n",
    "    comp_name = [\"x\", \"y\", \"z\"][dim]\n",
    "    ylabel = f\"PSD – {DIM_LABELS[dim]}\"\n",
    "\n",
    "    # --- one figure per model ---\n",
    "    for m in scenario_models:\n",
    "        preds = pred_store[(m, init_id, split, rho, seed)][:T]\n",
    "        f_p, P_p = signal.welch(preds[:, dim], fs=fs, window=window,\n",
    "                                nperseg=nperseg_eff, noverlap=noverlap,\n",
    "                                detrend=detrend, scaling=scaling, return_onesided=True)\n",
    "\n",
    "        plt.figure(figsize=(9.5, 4.2))\n",
    "        # truth (dotted) + model\n",
    "        plt.plot(f_t, P_t, linestyle=\":\", lw=2.2, color=truth_color, label=\"Ground truth\")\n",
    "        plt.plot(f_p, P_p, lw=1.7, color=palette.get(m, \"C0\"), label=m)\n",
    "\n",
    "        plt.xlabel(\"Frequency (Hz)\")\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlim(0, 10)   # <-- limit frequency axis to 10 Hz\n",
    "        plt.grid(alpha=0.25)\n",
    "        plt.legend(frameon=False)\n",
    "        #plt.title(f\"PSD — {m} vs Truth | {DIM_LABELS[dim]}  •  init={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        safe_model = m.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "        out = FIG_DIR / f\"psd_{SYSTEM}_{safe_model}_dim-{comp_name}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "        plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "        print(f\"Saved: {out}\")\n",
    "\n",
    "# All models, separate figures, PSD for x only\n",
    "plot_psd_all_models_separate(pred_store, DATA, init_id=1, split=0.8, rho=0.95, seed=1, dim=0)\n",
    "\n",
    "# For y (dim=1)\n",
    "#plot_psd_all_models_separate(pred_store, DATA, init_id=1, split=0.8, rho=0.95, seed=1, dim=1)\n",
    "\n",
    "# For z (dim=2), longer segment and larger nperseg\n",
    "#plot_psd_all_models_separate(pred_store, DATA, init_id=1, split=0.8, rho=0.95, seed=1, dim=2, max_len=6000, nperseg=2048)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2df555-7875-491e-ac75-d0675cfa5f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Time-series overlays with VPT (no truth recompute)\n",
    "# =========================================================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "TRUTH_COLOR = \"#3b3b3b\"  # dotted charcoal for ground truth\n",
    "\n",
    "# --- System-specific λ_max defaults (fallback if auto fails) ---\n",
    "LAMBDA_MODE = \"auto\"   # \"auto\" or \"fixed\"\n",
    "LAMBDA_MAP  = {\n",
    "    \"lorenz\":    0.90,\n",
    "    \"rossler\":   0.07,     # typical for (a=0.2,b=0.2,c=5.7) with dt≈0.02\n",
    "    \"chen-ueta\": 2.038,\n",
    "}\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name=\"colorblind\"):\n",
    "    \"\"\"Palette only for models that exist for this scenario.\"\"\"\n",
    "    models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    pal = sns.color_palette(palette_name, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "# ------------------------------\n",
    "# Rough λ_max (Rosenstein-style)\n",
    "# ------------------------------\n",
    "def estimate_lambda_max_rosenstein(y_true: np.ndarray, t: np.ndarray,\n",
    "                                  theiler: int = 30, kmax: int = 60,\n",
    "                                  n_samples: int = 500) -> float:\n",
    "    \"\"\"\n",
    "    Very lightweight largest Lyapunov exponent estimate from a single trajectory.\n",
    "    y_true: (T, d) trajectory; t: time vector. Returns λ_max in 1/seconds.\n",
    "    \"\"\"\n",
    "    T, d = y_true.shape\n",
    "    if T < theiler + kmax + 2:\n",
    "        raise ValueError(\"Time series too short for λ_max estimation\")\n",
    "\n",
    "    # nearest neighbors with exclusion window\n",
    "    nbrs = NearestNeighbors(n_neighbors=10, algorithm=\"auto\").fit(y_true)\n",
    "    # sample candidate anchors away from ends\n",
    "    rng = np.random.default_rng(0)\n",
    "    anchors = rng.integers(low=theiler+1, high=T-kmax-1, size=min(n_samples, T - (theiler+kmax+2)))\n",
    "\n",
    "    dt = float(np.mean(np.diff(t)))\n",
    "    logs = []\n",
    "\n",
    "    for i in anchors:\n",
    "        # find a neighbor not within Theiler window\n",
    "        dists, idxs = nbrs.kneighbors(y_true[i:i+1], return_distance=True)\n",
    "        j = None\n",
    "        for cand in idxs[0]:\n",
    "            if abs(cand - i) > theiler:\n",
    "                j = cand\n",
    "                break\n",
    "        if j is None:\n",
    "            continue\n",
    "\n",
    "        # separation growth\n",
    "        seq = []\n",
    "        for k in range(1, kmax+1):\n",
    "            if i+k >= T or j+k >= T:\n",
    "                break\n",
    "            d_k = np.linalg.norm(y_true[i+k] - y_true[j+k])\n",
    "            if d_k <= 0:\n",
    "                continue\n",
    "            seq.append(np.log(d_k))\n",
    "        if len(seq) >= 8:\n",
    "            logs.append(seq)\n",
    "\n",
    "    if not logs:\n",
    "        raise RuntimeError(\"Failed to collect separations for λ_max estimation\")\n",
    "\n",
    "    # pad to same length (use min length across collected sequences)\n",
    "    L = min(len(s) for s in logs)\n",
    "    M = np.stack([s[:L] for s in logs], axis=0)  # (N, L)\n",
    "    y = M.mean(axis=0)                           # ⟨log d(k)⟩\n",
    "    x = np.arange(1, L+1) * dt                   # time in seconds\n",
    "\n",
    "    # fit only early linear region (first 1/3 or up to ~0.5s)\n",
    "    cutoff = max(10, min(L//3, int(0.5/dt)))\n",
    "    if cutoff < 6: cutoff = min(L, 10)\n",
    "    coef = np.polyfit(x[:cutoff], y[:cutoff], 1)  # slope ≈ λ_max\n",
    "    lam = float(coef[0])\n",
    "    return max(lam, 1e-6)\n",
    "\n",
    "def get_lambda_max(system: str, y_true: np.ndarray, t: np.ndarray) -> float:\n",
    "    \"\"\"Select λ_max based on LAMBDA_MODE & map; auto falls back to map.\"\"\"\n",
    "    sys_key = (system or \"lorenz\").lower()\n",
    "    if LAMBDA_MODE.lower() == \"fixed\":\n",
    "        return float(LAMBDA_MAP.get(sys_key, 0.9))\n",
    "    # auto\n",
    "    try:\n",
    "        return estimate_lambda_max_rosenstein(y_true, t)\n",
    "    except Exception:\n",
    "        return float(LAMBDA_MAP.get(sys_key, 0.9))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Main plotter (uses DATA cache for ORIGINAL truth only)\n",
    "# ---------------------------------------------------------\n",
    "def plot_timeseries_with_vpt_per_model(pred_store, DATA, model,\n",
    "                                       init_id, split, rho, seed,\n",
    "                                       system=\"lorenz\",\n",
    "                                       threshold=0.4,\n",
    "                                       lambda_mode=None,   # override global if not None\n",
    "                                       max_len=None, dpi=300,\n",
    "                                       palette_name=\"colorblind\",\n",
    "                                       truth_color=TRUTH_COLOR):\n",
    "    \"\"\"\n",
    "    One figure per (model, scenario): 3 stacked panels (x,y,z).\n",
    "    Uses DATA[(init_id, split)] to fetch ORIGINAL test trajectory.\n",
    "    Draws VPT vertical line based on (threshold, λ_max).\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "\n",
    "    t        = DATA[ds_key][\"time_test\"]\n",
    "    y_true   = DATA[ds_key][\"test_y\"]\n",
    "    key      = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred   = pred_store[key]\n",
    "\n",
    "    # Align lengths\n",
    "    T = min(len(t), len(y_true), len(y_pred))\n",
    "    if max_len is not None:\n",
    "        T = min(T, max_len)\n",
    "    t = t[:T]; y_true = y_true[:T]; y_pred = y_pred[:T]\n",
    "\n",
    "    # λ_max selection\n",
    "    mode = (lambda_mode or LAMBDA_MODE).lower()\n",
    "    lam  = get_lambda_max(system, y_true, t) if mode == \"auto\" else float(LAMBDA_MAP.get(system.lower(), 0.9))\n",
    "\n",
    "    # Compute VPT\n",
    "    T_VPT, T_lambda, ratio = compute_valid_prediction_time(\n",
    "        y_true, y_pred, t, threshold=threshold, lambda_max=lam\n",
    "    )\n",
    "    vline_x = np.clip(T_VPT, t[0], t[-1])\n",
    "\n",
    "    # palette per scenario so color is consistent across figures\n",
    "    scenario_palette = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color_model = scenario_palette.get(model, \"C0\")\n",
    "\n",
    "    # Plot\n",
    "    dim_names = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(11, 8), sharex=True)\n",
    "    for d, ax in enumerate(axes):\n",
    "        ax.plot(t, y_true[:, d], linestyle=\":\", color=truth_color, lw=1.9, label=\"Ground truth\")\n",
    "        ax.plot(t, y_pred[:, d], color=color_model, lw=1.5, label=model)\n",
    "        ax.axvline(vline_x, color=\"crimson\", ls=\"--\", lw=1.2,\n",
    "                   label=(f\"VPT={T_VPT:.2f}s\" if d == 0 else None))\n",
    "        ax.set_ylabel(dim_names[d]); ax.grid(alpha=0.25)\n",
    "        if d == 0:\n",
    "            ax.legend(ncol=3, frameon=False)\n",
    "    axes[-1].set_xlabel(\"Time (s)\")\n",
    "    plt.suptitle(f\"{model}: Trajectory vs Truth  |  init={init_id}, split={split}, ρ={rho}, seed={seed}  •  \"\n",
    "                 f\"λ_max=({mode}) {lam:.3g}, threshold={threshold}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "\n",
    "    out = FIG_DIR / f\"{system}_ts_vpt_{_safe_name(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "'''plot_timeseries_with_vpt_per_model(\n",
    "    pred_store, DATA,\n",
    "    model=\"ESN\",\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    system=SYSTEM,          # e.g., \"lorenz\" | \"rossler\" | \"chen-ueta\"\n",
    "    threshold=0.4,\n",
    "    lambda_mode=\"auto\",     # or \"fixed\"\n",
    "    max_len=2000, dpi=300\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4c35a-931a-4652-b01e-034e2768ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Phase-space overlay (per model) — no re-gen\n",
    "# ============================================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "TRUTH_COLOR = \"#3b3b3b\"  # dotted charcoal for ground truth\n",
    "\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name=\"colorblind\"):\n",
    "    \"\"\"Palette only for models that exist for this scenario.\"\"\"\n",
    "    models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    pal = sns.color_palette(palette_name, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "def plot_phase_space_overlay_per_model(pred_store, DATA, model,\n",
    "                                       init_id, split, rho, seed,\n",
    "                                       max_len=4000, dpi=300,\n",
    "                                       truth_color=TRUTH_COLOR,\n",
    "                                       palette_name=\"colorblind\"):\n",
    "    \"\"\"\n",
    "    One figure per model:\n",
    "      • 3D Lorenz/Rössler/Chen-Ueta trajectory overlay (truth dotted)\n",
    "      • 2D projections (x–y, y–z, x–z)\n",
    "    Uses ORIGINAL test trajectory from DATA cache: DATA[(init_id, split)].\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "\n",
    "    # Truth & preds (no recomputation)\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    # Align lengths\n",
    "    T = min(len(y_true), len(y_pred), max_len if max_len else len(y_true))\n",
    "    y_true = y_true[:T]; y_pred = y_pred[:T]\n",
    "\n",
    "    # Colors\n",
    "    pal = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color_model = pal.get(model, \"C0\")\n",
    "\n",
    "    # Layout: 2x2 (3D top-left, then XY, YZ, XZ projections)\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = GridSpec(2, 2, figure=fig, height_ratios=[2.0, 1.6])\n",
    "\n",
    "    # 3D\n",
    "    ax3d = fig.add_subplot(gs[0, 0], projection='3d')\n",
    "    ax3d.plot(y_true[:,0], y_true[:,1], y_true[:,2], ls=\":\", lw=1.8, color=truth_color, label=\"Ground truth\")\n",
    "    ax3d.plot(y_pred[:,0], y_pred[:,1], y_pred[:,2], lw=1.4, color=color_model, label=model)\n",
    "    ax3d.set_xlabel(\"x\"); ax3d.set_ylabel(\"y\"); ax3d.set_zlabel(\"z\")\n",
    "    ax3d.legend(frameon=False)\n",
    "\n",
    "    # XY\n",
    "    ax_xy = fig.add_subplot(gs[0, 1])\n",
    "    ax_xy.plot(y_true[:,0], y_true[:,1], ls=\":\", lw=1.8, color=truth_color)\n",
    "    ax_xy.plot(y_pred[:,0], y_pred[:,1], lw=1.4, color=color_model)\n",
    "    ax_xy.set_xlabel(\"x\"); ax_xy.set_ylabel(\"y\"); ax_xy.set_title(\"x–y\")\n",
    "    ax_xy.set_aspect(\"equal\", adjustable=\"box\"); ax_xy.grid(alpha=0.25)\n",
    "\n",
    "    # YZ\n",
    "    ax_yz = fig.add_subplot(gs[1, 0])\n",
    "    ax_yz.plot(y_true[:,1], y_true[:,2], ls=\":\", lw=1.8, color=truth_color)\n",
    "    ax_yz.plot(y_pred[:,1], y_pred[:,2], lw=1.4, color=color_model)\n",
    "    ax_yz.set_xlabel(\"y\"); ax_yz.set_ylabel(\"z\"); ax_yz.set_title(\"y–z\")\n",
    "    ax_yz.set_aspect(\"equal\", adjustable=\"box\"); ax_yz.grid(alpha=0.25)\n",
    "\n",
    "    # XZ\n",
    "    ax_xz = fig.add_subplot(gs[1, 1])\n",
    "    ax_xz.plot(y_true[:,0], y_true[:,2], ls=\":\", lw=1.8, color=truth_color)\n",
    "    ax_xz.plot(y_pred[:,0], y_pred[:,2], lw=1.4, color=color_model)\n",
    "    ax_xz.set_xlabel(\"x\"); ax_xz.set_ylabel(\"z\"); ax_xz.set_title(\"x–z\")\n",
    "    ax_xz.set_aspect(\"equal\", adjustable=\"box\"); ax_xz.grid(alpha=0.25)\n",
    "\n",
    "    #plt.suptitle(f\"{model}: Phase-space overlay  |  init={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "    out = FIG_DIR / f\"phase_{_safe_name(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "plot_phase_space_overlay_per_model(\n",
    "    pred_store, DATA,\n",
    "    model=\"CHORD-ESN\", init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    max_len=1000, dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ebe49-b661-4fe4-a63b-1aa227ab9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Poincaré section (per model) — no re-gen of truth\n",
    "# ============================================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "TRUTH_COLOR = \"#3b3b3b\"  # dotted charcoal for ground truth\n",
    "\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name=\"colorblind\"):\n",
    "    \"\"\"Palette only for models that exist for this scenario.\"\"\"\n",
    "    models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    pal = sns.color_palette(palette_name, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "def _plane_crossings_xyz(x, y, z, x0, direction=\"up\"):\n",
    "    \"\"\"\n",
    "    Return intersection points (y*, z*) where x(t) crosses plane x=x0.\n",
    "    direction: \"up\" (below->above), \"down\" (above->below), or \"both\".\n",
    "    \"\"\"\n",
    "    y_pts, z_pts = [], []\n",
    "    for i in range(1, len(x)):\n",
    "        x_prev, x_curr = x[i-1], x[i]\n",
    "        # orientation filter\n",
    "        if direction == \"up\" and not (x_prev < x0 <= x_curr):\n",
    "            continue\n",
    "        if direction == \"down\" and not (x_prev > x0 >= x_curr):\n",
    "            continue\n",
    "        if direction == \"both\" and not ((x_prev - x0) * (x_curr - x0) <= 0):\n",
    "            continue\n",
    "        denom = x_curr - x_prev\n",
    "        if np.isclose(denom, 0.0):\n",
    "            continue\n",
    "        alpha = (x0 - x_prev) / denom  # linear interpolation weight\n",
    "        y_cross = y[i-1] + alpha * (y[i] - y[i-1])\n",
    "        z_cross = z[i-1] + alpha * (z[i] - z[i-1])\n",
    "        y_pts.append(y_cross); z_pts.append(z_cross)\n",
    "    return np.array(y_pts), np.array(z_pts)\n",
    "\n",
    "def plot_poincaré_section_per_model(pred_store, DATA, model,\n",
    "                                    init_id, split, rho, seed,\n",
    "                                    plane_axis=\"x\", plane_value=None,\n",
    "                                    direction=\"up\",\n",
    "                                    max_len=4000, dpi=300,\n",
    "                                    truth_color=TRUTH_COLOR,\n",
    "                                    palette_name=\"colorblind\"):\n",
    "    \"\"\"\n",
    "    Poincaré section for one model vs truth using ORIGINAL test trajectory from DATA.\n",
    "    plane_axis: {\"x\",\"y\",\"z\"}; section is axis = plane_value (defaults to mean of truth).\n",
    "    direction : {\"up\",\"down\",\"both\"} for crossing orientation.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "\n",
    "    # Truth & preds\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    # Align lengths\n",
    "    T = min(len(y_true), len(y_pred), max_len if max_len else len(y_true))\n",
    "    y_true = y_true[:T]; y_pred = y_pred[:T]\n",
    "\n",
    "    # Choose section axis & default value\n",
    "    ax_map = {\"x\": 0, \"y\": 1, \"z\": 2}\n",
    "    if plane_axis not in ax_map:\n",
    "        raise ValueError(\"plane_axis must be one of {'x','y','z'}\")\n",
    "    a = ax_map[plane_axis]\n",
    "\n",
    "    if plane_value is None:\n",
    "        plane_value = float(np.mean(y_true[:, a]))\n",
    "\n",
    "    # Rotate coordinates so section is always along the first component\n",
    "    # (re-use the existing x-plane crossing routine)\n",
    "    def _reorder(arr):\n",
    "        if a == 0:  # x-plane: (x,y,z)\n",
    "            return arr[:,0], arr[:,1], arr[:,2]\n",
    "        if a == 1:  # y-plane: (y,z,x) -> crossings return (z*, x*)\n",
    "            return arr[:,1], arr[:,2], arr[:,0]\n",
    "        else:       # z-plane: (z,x,y) -> crossings return (x*, y*)\n",
    "            return arr[:,2], arr[:,0], arr[:,1]\n",
    "\n",
    "    # Crossings\n",
    "    xt, yt, zt = _reorder(y_true)\n",
    "    xp, yp, zp = _reorder(y_pred)\n",
    "\n",
    "    YT, ZT = _plane_crossings_xyz(xt, yt, zt, plane_value, direction=direction)\n",
    "    YP, ZP = _plane_crossings_xyz(xp, yp, zp, plane_value, direction=direction)\n",
    "\n",
    "    # Pretty axis labels after reordering\n",
    "    pair_labels = {0: (\"y\", \"z\"), 1: (\"z\", \"x\"), 2: (\"x\", \"y\")}\n",
    "    lab_y, lab_z = pair_labels[a]\n",
    "\n",
    "    # Colors\n",
    "    pal = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color_model = pal.get(model, \"C0\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(7.2, 6.2))\n",
    "    if len(YT) == 0 and len(YP) == 0:\n",
    "        plt.text(0.5, 0.5,\n",
    "                 f\"No crossings found at {plane_axis}={plane_value:.2f} ({direction})\",\n",
    "                 ha=\"center\", va=\"center\")\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        if len(YT) > 0:\n",
    "            plt.scatter(YT, ZT, s=20, c=truth_color, alpha=0.75, marker=\"o\", label=\"Ground truth\")\n",
    "        if len(YP) > 0:\n",
    "            plt.scatter(YP, ZP, s=22, c=color_model, alpha=0.75, marker=\"x\", label=model)\n",
    "        plt.xlabel(f\"{lab_y} at crossing\"); plt.ylabel(f\"{lab_z} at crossing\")\n",
    "        plt.title(f\"Poincaré: {plane_axis}={plane_value:.2f} ({direction})\\n\"\n",
    "                  f\"{model}  |  init={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "        plt.legend(frameon=False)\n",
    "        plt.grid(alpha=0.25)\n",
    "        plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / f\"poincare_{_safe_name(model)}_{plane_axis}{plane_value:.2f}_{direction}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "# Default: section on mean(x_true), upward crossings\n",
    "'''plot_poincaré_section_per_model(\n",
    "    pred_store, DATA, \"CHORDESN\",\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    plane_axis=\"x\", direction=\"up\"\n",
    ")'''\n",
    "\n",
    "# Specific plane & both directions on y=10.0\n",
    "'''plot_poincaré_section_per_model(\n",
    "    pred_store, DATA, \"ESN\",\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    plane_axis=\"y\", plane_value=10.0, direction=\"both\"\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45298ceb-5747-4779-9285-b30a0ae82e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ setup & helpers ============================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "TRUTH_COLOR = \"#3b3b3b\"\n",
    "\n",
    "\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name=\"colorblind\"):\n",
    "    \"\"\"Palette only for models present in this exact scenario.\"\"\"\n",
    "    models = sorted({\n",
    "        m for (m, i, s, r, sd) in pred_store.keys()\n",
    "        if (i, s, r, sd) == (init_id, split, rho, seed)\n",
    "    })\n",
    "    pal = sns.color_palette(palette_name, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "# Simple (biased) ACF up to nlags\n",
    "def _acf(x, nlags=200):\n",
    "    x = np.asarray(x, float)\n",
    "    x = x - np.mean(x)\n",
    "    n = len(x)\n",
    "    if n == 0:\n",
    "        return np.array([np.nan]*(nlags+1))\n",
    "    denom = np.dot(x, x)\n",
    "    if denom == 0:\n",
    "        return np.array([0.0] + [0.0]*nlags)\n",
    "    ac = [1.0]\n",
    "    for k in range(1, nlags+1):\n",
    "        num = np.dot(x[k:], x[:n-k])\n",
    "        ac.append(num / denom)\n",
    "    return np.array(ac)\n",
    "\n",
    "# ============================ plots (DATA-driven) ============================\n",
    "\n",
    "def plot_residual_hist_kde_per_model(pred_store, DATA, model,\n",
    "                                     init_id, split, rho, seed,\n",
    "                                     max_len=None, bins=50, dpi=300,\n",
    "                                     palette_name=\"colorblind\"):\n",
    "    \"\"\"\n",
    "    Residual histogram + KDE (ŷ−y) per dimension, using ORIGINAL test_y from DATA.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    if max_len is not None:\n",
    "        T = min(T, max_len)\n",
    "    y_true, y_pred = y_true[:T], y_pred[:T]\n",
    "    resid = y_pred - y_true\n",
    "\n",
    "    dim_names = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "    pal = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color = pal.get(model, \"C0\")\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 8), sharex=False)\n",
    "    for d, ax in enumerate(axes):\n",
    "        sns.histplot(resid[:, d], bins=bins, stat=\"density\", kde=True,\n",
    "                     color=color, alpha=0.35, edgecolor=None, ax=ax)\n",
    "        ax.axvline(0.0, color=TRUTH_COLOR, ls=\":\", lw=1.5)\n",
    "        ax.set_ylabel(f\"Density ({dim_names[d]})\")\n",
    "        ax.grid(alpha=0.25)\n",
    "    axes[-1].set_xlabel(\"Residual (ŷ − y)\")\n",
    "    plt.suptitle(f\"Residual distribution (hist + KDE) — {model}\\ninit={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.93])\n",
    "    out = FIG_DIR / f\"resid_hist_kde_{_safe_name(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "def plot_residual_acf_per_model(pred_store, DATA, model,\n",
    "                                init_id, split, rho, seed,\n",
    "                                nlags=200, max_len=None, dpi=300,\n",
    "                                palette_name=\"colorblind\"):\n",
    "    \"\"\"\n",
    "    Residual ACF per dimension using ORIGINAL test_y from DATA.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    if max_len is not None:\n",
    "        T = min(T, max_len)\n",
    "    resid = (y_pred - y_true)[:T]\n",
    "\n",
    "    dim_names = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "    pal = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color = pal.get(model, \"C0\")\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
    "    for d, ax in enumerate(axes):\n",
    "        r = _acf(resid[:, d], nlags=nlags)\n",
    "        ax.bar(np.arange(len(r)), r, color=color, width=0.8)\n",
    "        ax.axhline(0, color=TRUTH_COLOR, lw=1.0)\n",
    "        ax.set_xlim(-0.5, nlags+0.5)\n",
    "        ax.set_ylabel(f\"ACF ({dim_names[d]})\")\n",
    "        ax.grid(alpha=0.25)\n",
    "    axes[-1].set_xlabel(\"Lag\")\n",
    "    plt.suptitle(f\"Residual ACF — {model}\\ninit={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.93])\n",
    "    out = FIG_DIR / f\"resid_acf_{_safe_name(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "def plot_parity_density_per_model(pred_store, DATA, model,\n",
    "                                  init_id, split, rho, seed,\n",
    "                                  max_points=20000, dpi=300,\n",
    "                                  cmap=\"Blues\", palette_name=\"colorblind\"):\n",
    "    \"\"\"\n",
    "    Parity plots (ŷ vs y) with density background (KDE) + slope & R² per dimension.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    y_true, y_pred = y_true[:T], y_pred[:T]\n",
    "\n",
    "    # (optional) subsample for speed\n",
    "    if T > max_points:\n",
    "        idx = np.linspace(0, T-1, max_points).astype(int)\n",
    "        y_true = y_true[idx]; y_pred = y_pred[idx]\n",
    "\n",
    "    dim_names = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "    pal = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color = pal.get(model, \"C0\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(13, 4.4))\n",
    "    for d, ax in enumerate(axes):\n",
    "        # density background\n",
    "        sns.kdeplot(x=y_true[:, d], y=y_pred[:, d], fill=True, levels=30,\n",
    "                    cmap=cmap, thresh=0.02, ax=ax)\n",
    "        # parity line\n",
    "        lim = [min(y_true[:, d].min(), y_pred[:, d].min()),\n",
    "               max(y_true[:, d].max(), y_pred[:, d].max())]\n",
    "        ax.plot(lim, lim, ls=\":\", color=TRUTH_COLOR, lw=1.5, label=\"y = x\")\n",
    "        # fit slope & R²\n",
    "        slope, intercept = np.polyfit(y_true[:, d], y_pred[:, d], 1)\n",
    "        r = np.corrcoef(y_true[:, d], y_pred[:, d])[0,1]\n",
    "        r2 = r*r\n",
    "        ax.plot(lim, slope*np.array(lim) + intercept, color=color, lw=1.8,\n",
    "                label=f\"slope={slope:.2f}, R²={r2:.3f}\")\n",
    "        ax.set_xlabel(\"y (truth)\"); ax.set_ylabel(\"ŷ (pred)\")\n",
    "        ax.set_title(f\"Parity — {dim_names[d]}\")\n",
    "        ax.legend(frameon=False); ax.grid(alpha=0.25)\n",
    "\n",
    "    plt.suptitle(f\"Parity with density — {model}\\ninit={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.90])\n",
    "    out = FIG_DIR / f\"parity_density_{_safe_name(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "def plot_bland_altman_per_model(pred_store, DATA, model,\n",
    "                                init_id, split, rho, seed,\n",
    "                                max_len=None, dpi=300,\n",
    "                                palette_name=\"colorblind\"):\n",
    "    \"\"\"\n",
    "    Bland–Altman plots (mean vs difference) per dimension.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    if max_len is not None:\n",
    "        T = min(T, max_len)\n",
    "    y_true, y_pred = y_true[:T], y_pred[:T]\n",
    "\n",
    "    dim_names = [\"x(t)\", \"y(t)\", \"z(t)\"]\n",
    "    pal = make_model_palette_for_scenario(pred_store, init_id, split, rho, seed, palette_name)\n",
    "    color = pal.get(model, \"C0\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(13, 4.4))\n",
    "    for d, ax in enumerate(axes):\n",
    "        mean_vals = 0.5 * (y_true[:, d] + y_pred[:, d])\n",
    "        diff_vals = y_pred[:, d] - y_true[:, d]\n",
    "        md = np.mean(diff_vals)\n",
    "        sd = np.std(diff_vals, ddof=1)\n",
    "        loa_low, loa_high = md - 1.96*sd, md + 1.96*sd\n",
    "\n",
    "        sns.scatterplot(x=mean_vals, y=diff_vals, s=12, alpha=0.5, color=color, edgecolor=None, ax=ax)\n",
    "        ax.axhline(md, color=TRUTH_COLOR, lw=1.5, ls=\"--\", label=f\"mean={md:.3g}\")\n",
    "        ax.axhline(loa_low, color=\"crimson\", lw=1.0, ls=\"--\", label=f\"LoA={loa_low:.3g}\")\n",
    "        ax.axhline(loa_high, color=\"crimson\", lw=1.0, ls=\"--\", label=f\"HiA={loa_high:.3g}\")\n",
    "\n",
    "        ax.set_xlabel(\"Mean of (y, ŷ)\")\n",
    "        ax.set_ylabel(\"Difference (ŷ − y)\")\n",
    "        ax.set_title(f\"Bland–Altman — {dim_names[d]}\")\n",
    "        ax.grid(alpha=0.25); ax.legend(frameon=False)\n",
    "\n",
    "    plt.suptitle(f\"Bland–Altman — {model}\\ninit={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.90])\n",
    "    out = FIG_DIR / f\"bland_altman_{_safe_name(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "# Residual distribution\n",
    "plot_residual_hist_kde_per_model(pred_store, DATA, \"Cycle\",\n",
    "                                 init_id=1, split=0.8, rho=0.95, seed=1)\n",
    "\n",
    "# Residual ACF\n",
    "plot_residual_acf_per_model(pred_store, DATA, \"CHORD-ESN\",\n",
    "                            init_id=1, split=0.8, rho=0.95, seed=1, nlags=150)\n",
    "\n",
    "# Parity with density\n",
    "plot_parity_density_per_model(pred_store, DATA, \"ESN\",\n",
    "                              init_id=1, split=0.8, rho=0.95, seed=1)\n",
    "\n",
    "# Bland–Altman\n",
    "plot_bland_altman_per_model(pred_store, DATA, \"CHORD-ESN\",\n",
    "                            init_id=1, split=0.8, rho=0.95, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a3315b-daf4-42f6-b8ee-bf7f85ad41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "TRUTH_COLOR = \"#3b3b3b\"\n",
    "\n",
    "\n",
    "\n",
    "def plot_adev_heatmaps_per_model(pred_store, DATA, model,\n",
    "                                 init_id, split, rho, seed,\n",
    "                                 bins=(40,40,40),     # (nx, ny, nz)\n",
    "                                 max_len=None, norm=True,\n",
    "                                 cmap=\"mako\", dpi=300,\n",
    "                                 vmin=0.0, vmax=None):\n",
    "    \"\"\"\n",
    "    ADev heatmaps (|Δ occupancy|) projected onto XY, YZ, XZ planes.\n",
    "\n",
    "    - Uses ORIGINAL test_y from DATA[(init_id, split)] (no recomputation).\n",
    "    - If `norm=True`, each 3D histogram is normalized to probability mass\n",
    "      before the absolute difference is taken.\n",
    "    - `vmin/vmax` let you fix a shared color scale across multiple calls.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "\n",
    "    y_true = DATA[ds_key][\"test_y\"]\n",
    "\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    # Align lengths\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    if max_len is not None:\n",
    "        T = min(T, max_len)\n",
    "    y_true = y_true[:T]\n",
    "    y_pred = y_pred[:T]\n",
    "\n",
    "    # Shared bin ranges for fairness\n",
    "    mins = np.minimum(y_true.min(axis=0), y_pred.min(axis=0))\n",
    "    maxs = np.maximum(y_true.max(axis=0), y_pred.max(axis=0))\n",
    "    ranges = [(mins[0], maxs[0]), (mins[1], maxs[1]), (mins[2], maxs[2])]\n",
    "\n",
    "    # 3D histograms (occupancies)\n",
    "    H_true, edges = np.histogramdd(y_true, bins=bins, range=ranges)\n",
    "    H_pred, _     = np.histogramdd(y_pred, bins=bins, range=ranges)\n",
    "\n",
    "    if norm:\n",
    "        s_true = H_true.sum()\n",
    "        s_pred = H_pred.sum()\n",
    "        if s_true > 0: H_true = H_true / s_true\n",
    "        if s_pred > 0: H_pred = H_pred / s_pred\n",
    "\n",
    "    Delta = np.abs(H_true - H_pred)          # (nx, ny, nz)\n",
    "    delta_sum = float(Delta.sum())\n",
    "\n",
    "    # 2D projections (sum over remaining axis)\n",
    "    delta_xy = Delta.sum(axis=2)  # (nx, ny)\n",
    "    delta_yz = Delta.sum(axis=0)  # (ny, nz)\n",
    "    delta_xz = Delta.sum(axis=1)  # (nx, nz)\n",
    "\n",
    "    # Plot heatmaps\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4.2))\n",
    "    # XY\n",
    "    sns.heatmap(delta_xy.T, ax=axes[0], cmap=cmap, cbar=True,\n",
    "                square=True, vmin=vmin, vmax=vmax,\n",
    "                cbar_kws=dict(label=\"|Δ| (proj. mass)\"))\n",
    "    axes[0].set_title(\"|Δ| occupancy: x–y\")\n",
    "    axes[0].set_xlabel(\"x-bins\"); axes[0].set_ylabel(\"y-bins\")\n",
    "\n",
    "    # YZ\n",
    "    sns.heatmap(delta_yz.T, ax=axes[1], cmap=cmap, cbar=True,\n",
    "                square=True, vmin=vmin, vmax=vmax,\n",
    "                cbar_kws=dict(label=\"|Δ| (proj. mass)\"))\n",
    "    axes[1].set_title(\"|Δ| occupancy: y–z\")\n",
    "    axes[1].set_xlabel(\"y-bins\"); axes[1].set_ylabel(\"z-bins\")\n",
    "\n",
    "    # XZ\n",
    "    sns.heatmap(delta_xz.T, ax=axes[2], cmap=cmap, cbar=True,\n",
    "                square=True, vmin=vmin, vmax=vmax,\n",
    "                cbar_kws=dict(label=\"|Δ| (proj. mass)\"))\n",
    "    axes[2].set_title(\"|Δ| occupancy: x–z\")\n",
    "    axes[2].set_xlabel(\"x-bins\"); axes[2].set_ylabel(\"z-bins\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"ADev heatmaps — {model}  |  init={init_id}, split={split}, ρ={rho}, seed={seed}\\n\"\n",
    "        f\"Total |Δ| (3D) = {delta_sum:.4f}\"\n",
    "    )\n",
    "    plt.tight_layout(rect=[0,0,1,0.90])\n",
    "\n",
    "    out = FIG_DIR / f\"adev_heatmaps_{model.replace(' ','').replace('/','_')}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "plot_adev_heatmaps_per_model(\n",
    "    pred_store, DATA, \"CHORD-ESN\",\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    bins=(40,40,40), max_len=4000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b34d3-a88d-492b-bbde-e69775972524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Recurrence plots (RP / Cross-RP) ==================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "\n",
    "\n",
    "TRUTH_COLOR = \"#3b3b3b\"\n",
    "\n",
    "def _downsample_idx(n, max_points=1500):\n",
    "    if n <= max_points:\n",
    "        return np.arange(n, dtype=int)\n",
    "    return np.linspace(0, n-1, max_points).astype(int)\n",
    "\n",
    "def _rp_binary(X, eps=None, quantile=0.1, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Binary recurrence plot: R_ij = 1[dist(X[i], X[j]) <= eps].\n",
    "    If eps is None, set eps to the `quantile` of pairwise distances.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    if X.ndim == 1:\n",
    "        X = X[:, None]\n",
    "    if len(X) < 2:\n",
    "        return np.ones((len(X), len(X))), 0.0\n",
    "\n",
    "    dvec = pdist(X, metric=metric)                 # condensed\n",
    "    D = squareform(dvec)                           # (T, T)\n",
    "    if eps is None:\n",
    "        eps = float(np.quantile(dvec, quantile)) if dvec.size else 0.0\n",
    "    R = (D <= eps).astype(float)\n",
    "    return R, eps\n",
    "\n",
    "def _cross_rp_binary(X, Y, eps=None, quantile=0.1, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Binary cross-recurrence: CR_ij = 1[dist(X[i], Y[j]) <= eps].\n",
    "    If eps is None, set eps from cross-distance quantile.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X); Y = np.asarray(Y)\n",
    "    if X.ndim == 1: X = X[:, None]\n",
    "    if Y.ndim == 1: Y = Y[:, None]\n",
    "    if len(X) == 0 or len(Y) == 0:\n",
    "        return np.zeros((len(X), len(Y))), 0.0\n",
    "\n",
    "    D = cdist(X, Y, metric=metric)                 # (Tx, Ty)\n",
    "    if eps is None:\n",
    "        eps = float(np.quantile(D, quantile)) if D.size else 0.0\n",
    "    CR = (D <= eps).astype(float)\n",
    "    return CR, eps\n",
    "\n",
    "def plot_recurrence_plots_per_model(pred_store, DATA, model,\n",
    "                                    init_id, split, rho, seed,\n",
    "                                    max_points=1200, metric=\"euclidean\",\n",
    "                                    q_truth=0.1, q_pred=0.1, q_cross=0.1,\n",
    "                                    cmap=\"Greys\", dpi=300):\n",
    "    \"\"\"\n",
    "    Three panels: RP(true), RP(pred), Cross-RP(true vs pred).\n",
    "    Uses ORIGINAL test target from DATA[(init_id, split)].\n",
    "    Downsamples to <= max_points for O(n^2) feasibility.\n",
    "    \"\"\"\n",
    "    ds_key = (init_id, split)\n",
    "    if ds_key not in DATA:\n",
    "        raise KeyError(f\"No DATA cache for (init={init_id}, split={split}).\")\n",
    "\n",
    "    y_true_full = DATA[ds_key][\"test_y\"]\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred_full = pred_store[key]\n",
    "\n",
    "    # Align & downsample\n",
    "    T = min(len(y_true_full), len(y_pred_full))\n",
    "    idx = _downsample_idx(T, max_points=max_points)\n",
    "    y_true = y_true_full[:T][idx]\n",
    "    y_pred = y_pred_full[:T][idx]\n",
    "\n",
    "    # Build RPs\n",
    "    R_true,  eps_t  = _rp_binary(y_true, eps=None, quantile=q_truth, metric=metric)\n",
    "    R_pred,  eps_p  = _rp_binary(y_pred, eps=None, quantile=q_pred,  metric=metric)\n",
    "    CR,      eps_cp = _cross_rp_binary(y_true, y_pred, eps=None, quantile=q_cross, metric=metric)\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4.2))\n",
    "    for ax, M, ttl in [\n",
    "        (axes[0], R_true, f\"RP (Truth)\\nε={eps_t:.3g}\"),\n",
    "        (axes[1], R_pred, f\"RP (Pred)\\nε={eps_p:.3g}\"),\n",
    "        (axes[2], CR,     f\"Cross-RP (Truth vs Pred)\\nε={eps_cp:.3g}\"),\n",
    "    ]:\n",
    "        sns.heatmap(M, ax=ax, cmap=cmap, cbar=False, square=True)\n",
    "        ax.set_title(ttl)\n",
    "        ax.set_xlabel(\"t\"); ax.set_ylabel(\"t\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Recurrence plots — {model}  |  init={init_id}, split={split}, ρ={rho}, seed={seed}\\n\"\n",
    "        f\"(downsampled to {len(idx)} points)\"\n",
    "    )\n",
    "    plt.tight_layout(rect=[0,0,1,0.90])\n",
    "\n",
    "    out = FIG_DIR / f\"rp_{model.replace(' ','').replace('/','_')}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "# ADev heatmaps \n",
    "'''plot_adev_heatmaps_per_model(\n",
    "    pred_store, DATA, \"Cycle\",\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    bins=(40,40,40), max_len=4000\n",
    ")'''\n",
    "\n",
    "# Recurrence plots (truth RP, pred RP, cross-RP)\n",
    "plot_recurrence_plots_per_model(\n",
    "    pred_store, DATA, \"CHORD-ESN\",\n",
    "    init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "    max_points=1200, metric=\"euclidean\",\n",
    "    q_truth=0.1, q_pred=0.1, q_cross=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120ea13-f711-4cb2-b334-00d9c6b401a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "def _safe(s): return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def _get_W_matrix(model):\n",
    "    \"\"\"\n",
    "    Try to fetch the reservoir recurrent matrix from common attribute names.\n",
    "    Returns a dense ndarray or raises.\n",
    "    \"\"\"\n",
    "    for name in [\"W\", \"W_res\", \"W_base\", \"W_nn\", \"A\", \"adj\", \"Wrec\", \"W_cc\"]:\n",
    "        if hasattr(model, name):\n",
    "            W = getattr(model, name)\n",
    "            try:\n",
    "                import scipy.sparse as sp\n",
    "                if sp.issparse(W):\n",
    "                    W = W.toarray()\n",
    "            except Exception:\n",
    "                pass\n",
    "            W = np.asarray(W)\n",
    "            if W.ndim == 2 and W.shape[0] == W.shape[1]:\n",
    "                return W\n",
    "    raise AttributeError(f\"Could not find a recurrent matrix on {type(model).__name__}\")\n",
    "\n",
    "def plot_eigenspectrum_models(BASELINES, TESTING_RES_CLASS, rho=0.95, seed=0,\n",
    "                              add_hist=True, ncols=3, dpi=300):\n",
    "    \"\"\"\n",
    "    One panel per model: eigenvalues in C, with unit circle. Optionally add a\n",
    "    small radial histogram of |λ|.\n",
    "    \"\"\"\n",
    "    factories = dict(BASELINES)  # copy\n",
    "    if TESTING_RES_CLASS is not None:\n",
    "        #factories[\"Testing\"] = lambda r, s: TESTING_RES_CLASS(spectral_radius=r, seed=s)\n",
    "        factories[TESTING_NAME] = lambda r, s: TESTING_RES_CLASS(spectral_radius_cc=r, seed=s)\n",
    "\n",
    "\n",
    "    names = list(factories.keys())\n",
    "    n = len(names)\n",
    "    ncols = min(ncols, n)\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4.8*ncols, 4.4*nrows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    theta = np.linspace(0, 2*np.pi, 512)\n",
    "    unit = np.exp(1j*theta)\n",
    "\n",
    "    for idx, name in enumerate(names):\n",
    "        r, c = divmod(idx, ncols)\n",
    "        ax = axes[r, c]\n",
    "        try:\n",
    "            model = factories[name](rho, seed)\n",
    "            W = _get_W_matrix(model)\n",
    "            eig = np.linalg.eigvals(W)\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Failed:\\n{e}\", ha=\"center\", va=\"center\")\n",
    "            ax.axis(\"off\"); continue\n",
    "\n",
    "        ax.scatter(eig.real, eig.imag, s=10, alpha=0.7)\n",
    "        ax.plot(unit.real, unit.imag, \"k--\", lw=1.0, alpha=0.8)\n",
    "        ax.axhline(0, color=\"#888\", lw=0.6); ax.axvline(0, color=\"#888\", lw=0.6)\n",
    "        ax.set_title(name)\n",
    "        ax.set_xlabel(\"Re(λ)\"); ax.set_ylabel(\"Im(λ)\")\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "        if not add_hist: # histogram is unnecessary\n",
    "            inset = ax.inset_axes([0.65, 0.65, 0.32, 0.32])\n",
    "            inset.hist(np.abs(eig), bins=30, density=True, alpha=0.8)\n",
    "            inset.axvline(1.0, color=\"k\", ls=\"--\", lw=1.0)\n",
    "            inset.set_title(\"|λ|\", fontsize=9)\n",
    "            inset.set_yticks([])\n",
    "\n",
    "    # hide unused axes\n",
    "    for j in range(n, nrows*ncols):\n",
    "        r, c = divmod(j, ncols)\n",
    "        axes[r, c].axis(\"off\")\n",
    "\n",
    "    #plt.suptitle(f\"Eigen-spectrum (ρ={rho}, seed={seed})\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / f\"eigenspectrum_grid_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "plot_eigenspectrum_models(BASELINES, TESTING_RES_CLASS, rho=0.95, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff0adb-c426-4f4d-b710-528c79993eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "\n",
    "def _safe(s: str) -> str:\n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def _get_W_matrix(model):\n",
    "    \"\"\"\n",
    "    Try common attribute names for the (square) recurrent matrix.\n",
    "    Returns a dense ndarray or raises AttributeError.\n",
    "    \"\"\"\n",
    "    for name in [\"W\", \"W_res\", \"W_base\", \"W_nn\", \"A\", \"adj\", \"Wrec\", \"W_cc\"]:\n",
    "        if hasattr(model, name):\n",
    "            W = getattr(model, name)\n",
    "            try:\n",
    "                import scipy.sparse as sp\n",
    "                if sp.issparse(W):\n",
    "                    W = W.toarray()\n",
    "            except Exception:\n",
    "                pass\n",
    "            W = np.asarray(W)\n",
    "            if W.ndim == 2 and W.shape[0] == W.shape[1]:\n",
    "                return W\n",
    "    raise AttributeError(f\"Could not find a recurrent matrix on {type(model).__name__}\")\n",
    "\n",
    "def _instantiate(factory_or_class, rho, seed):\n",
    "    \"\"\"\n",
    "    Robustly instantiate either a factory (callable) or a class with (rho, seed).\n",
    "    Tries a few common constructor signatures.\n",
    "    \"\"\"\n",
    "    # If it's a simple factory: assume (rho, seed)\n",
    "    if not inspect.isclass(factory_or_class):\n",
    "        return factory_or_class(rho, seed)\n",
    "\n",
    "    # It's a class: try several signatures\n",
    "    cls = factory_or_class\n",
    "    tried = []\n",
    "    for kwargs in [\n",
    "        {\"spectral_radius\": rho, \"seed\": seed},\n",
    "        {\"rho\": rho, \"seed\": seed},\n",
    "        {\"rho_mix\": rho, \"rho_theta\": rho, \"rho_gamma\": rho, \"seed\": seed},\n",
    "        {\"seed\": seed},\n",
    "        {},\n",
    "    ]:\n",
    "        try:\n",
    "            return cls(**kwargs)\n",
    "        except TypeError as e:\n",
    "            tried.append((kwargs, str(e)))\n",
    "            continue\n",
    "    # If we get here, all attempts failed\n",
    "    msgs = \"\\n\".join([f\"  tried {k} -> {m}\" for k, m in tried])\n",
    "    raise TypeError(f\"Could not instantiate {cls.__name__} with rho={rho}, seed={seed}.\\n{msgs}\")\n",
    "\n",
    "def plot_eigenspectrum_models(\n",
    "    BASELINES: dict,\n",
    "    TESTING_RES_CLASS=None,           # class or factory; optional\n",
    "    rho: float = 0.95,\n",
    "    seed: int = 0,\n",
    "    add_hist: bool = True,\n",
    "    ncols: int = 3,\n",
    "    dpi: int = 300,\n",
    "    max_points: int = 5000,           # downsample eigenvalues if huge\n",
    "):\n",
    "    \"\"\"\n",
    "    One panel per model: eigenvalues in C with unit circle; optional inset of |λ|.\n",
    "    Uses seaborn styling; saves a PNG in figures/.\n",
    "\n",
    "    BASELINES: dict[str, callable] where callable takes (rho, seed) and returns a model.\n",
    "    TESTING_RES_CLASS: optional class or factory to include as \"Testing\".\n",
    "    \"\"\"\n",
    "    factories = dict(BASELINES)  # copy\n",
    "    if TESTING_RES_CLASS is not None:\n",
    "        factories[TESTING_NAME] = lambda r, s: _instantiate(TESTING_RES_CLASS, r, s)\n",
    "\n",
    "    names = list(factories.keys())\n",
    "    n = len(names)\n",
    "    ncols = min(ncols, n)\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4.8 * ncols, 4.4 * nrows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    theta = np.linspace(0, 2*np.pi, 1024)\n",
    "    unit = np.exp(1j * theta)\n",
    "\n",
    "    for idx, name in enumerate(names):\n",
    "        r, c = divmod(idx, ncols)\n",
    "        ax = axes[r, c]\n",
    "\n",
    "        try:\n",
    "            model = factories[name](rho, seed)\n",
    "            W = _get_W_matrix(model)\n",
    "            eig = np.linalg.eigvals(W)\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f\"Failed:\\n{e}\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        # optional downsample for very large reservoirs\n",
    "        if eig.size > max_points:\n",
    "            sel = np.random.default_rng(seed).choice(eig.size, size=max_points, replace=False)\n",
    "            eig = eig[sel]\n",
    "\n",
    "        # scatter in complex plane (seaborn style)\n",
    "        df = pd.DataFrame({\"Re\": eig.real, \"Im\": eig.imag, \"mag\": np.abs(eig)})\n",
    "        sns.scatterplot(\n",
    "            data=df, x=\"Re\", y=\"Im\",\n",
    "            s=8, alpha=0.7, linewidth=0, ax=ax\n",
    "        )\n",
    "\n",
    "        # unit circle + axes\n",
    "        ax.plot(unit.real, unit.imag, \"k--\", lw=1.0, alpha=0.9)\n",
    "        ax.axhline(0, color=\"#888\", lw=0.7); ax.axvline(0, color=\"#888\", lw=0.7)\n",
    "\n",
    "        # equal aspect and symmetric limits with a small pad\n",
    "        lim = max(1.05, df[[\"Re\",\"Im\"]].abs().to_numpy().max() * 1.05)\n",
    "        ax.set_xlim(-lim, lim)\n",
    "        ax.set_ylim(-lim, lim)\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "        ax.set_title(name, pad=8)\n",
    "        ax.set_xlabel(\"Re(λ)\"); ax.set_ylabel(\"Im(λ)\")\n",
    "\n",
    "        # inset |λ| histogram using seaborn\n",
    "        if add_hist:\n",
    "            inset = ax.inset_axes([0.62, 0.58, 0.34, 0.34])\n",
    "            sns.histplot(df[\"mag\"], bins=30, stat=\"density\", element=\"step\", alpha=0.9, ax=inset)\n",
    "            inset.axvline(1.0, color=\"k\", ls=\"--\", lw=1.0)\n",
    "            inset.set_title(\"|λ|\", fontsize=9, pad=2)\n",
    "            inset.set_yticks([])\n",
    "            inset.grid(True, alpha=0.2)\n",
    "\n",
    "    # hide unused axes\n",
    "    for j in range(n, nrows * ncols):\n",
    "        r, c = divmod(j, ncols)\n",
    "        axes[r, c].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Eigen-spectrum (ρ={rho}, seed={seed})\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out = FIG_DIR / f\"eigenspectrum_grid_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "plot_eigenspectrum_models(BASELINES, TESTING_RES_CLASS, rho=0.95, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c81398-0ee1-4662-af3a-a0d43c306634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "def _safe(s): \n",
    "    return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def _get_W_matrix(model):\n",
    "    \"\"\"\n",
    "    Try to fetch the reservoir recurrent matrix from common attribute names.\n",
    "    Returns a dense ndarray or raises.\n",
    "    \"\"\"\n",
    "    for name in [\"W\", \"W_res\", \"W_base\", \"W_nn\", \"A\", \"adj\", \"Wrec\", \"W_cc\"]:\n",
    "        if hasattr(model, name):\n",
    "            W = getattr(model, name)\n",
    "            try:\n",
    "                import scipy.sparse as sp\n",
    "                if sp.issparse(W):\n",
    "                    W = W.toarray()\n",
    "            except Exception:\n",
    "                pass\n",
    "            W = np.asarray(W)\n",
    "            if W.ndim == 2 and W.shape[0] == W.shape[1]:\n",
    "                return W\n",
    "    raise AttributeError(f\"Could not find a recurrent matrix on {type(model).__name__}\")\n",
    "\n",
    "def plot_eigenspectrum_models(\n",
    "    BASELINES, \n",
    "    TESTING_RES_CLASS=None, \n",
    "    rho=0.95, \n",
    "    seed=0,\n",
    "    add_hist=True, \n",
    "    ncols=3, \n",
    "    dpi=300,\n",
    "    cmap=\"mako\",               # seaborn colormap name\n",
    "    title=None,\n",
    "    save_name=None\n",
    "):\n",
    "    \"\"\"\n",
    "    One panel per model: eigenvalues in ℂ with unit circle, colored by |λ|.\n",
    "    Optional inset histogram + KDE of |λ|.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build factory dict\n",
    "    factories = dict(BASELINES)  # copy (preserve your order)\n",
    "    if TESTING_RES_CLASS is not None:\n",
    "        #factories[\"Testing\"] = lambda r, s: TESTING_RES_CLASS(spectral_radius=r, seed=s)\n",
    "        factories[TESTING_NAME] = lambda r, s: TESTING_RES_CLASS(spectral_radius_cc=r, seed=s)\n",
    "\n",
    "\n",
    "    names = list(factories.keys())\n",
    "    n = len(names)\n",
    "    ncols = max(1, min(ncols, n))\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "    # Precompute eigenvalues so we can use consistent color scaling & limits\n",
    "    eig_map, max_abs = {}, 1.0\n",
    "    for name in names:\n",
    "        try:\n",
    "            model = factories[name](rho, seed)\n",
    "            W = _get_W_matrix(model)\n",
    "            eig = np.linalg.eigvals(W)\n",
    "            eig_map[name] = eig\n",
    "            max_abs = max(max_abs, float(np.abs(eig).max()))\n",
    "        except Exception as e:\n",
    "            eig_map[name] = e\n",
    "\n",
    "    # Figure + axes\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4.8*ncols, 4.4*nrows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "\n",
    "    # Unit circle\n",
    "    theta = np.linspace(0, 2*np.pi, 512)\n",
    "    unit = np.exp(1j * theta)\n",
    "\n",
    "    # Axes limits\n",
    "    rlim = max(1.05, 1.05 * max_abs)\n",
    "\n",
    "    # Colormap\n",
    "    import matplotlib as mpl\n",
    "    from matplotlib import cm\n",
    "    # Allow seaborn colormap strings\n",
    "    try:\n",
    "        cmap_obj = sns.color_palette(cmap, as_cmap=True)\n",
    "    except Exception:\n",
    "        cmap_obj = cm.get_cmap(cmap)\n",
    "\n",
    "    # Plot each model\n",
    "    for idx, name in enumerate(names):\n",
    "        r, c = divmod(idx, ncols)\n",
    "        ax = axes[r, c]\n",
    "        ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "        if isinstance(eig_map[name], Exception):\n",
    "            ax.text(0.5, 0.5, f\"Failed:\\n{eig_map[name]}\", ha=\"center\", va=\"center\")\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        eig = eig_map[name]\n",
    "        lam_abs = np.abs(eig)\n",
    "\n",
    "        sc = ax.scatter(eig.real, eig.imag, s=9, c=lam_abs, cmap=cmap_obj,\n",
    "                        alpha=0.9, linewidths=0)\n",
    "\n",
    "        # Unit circle + axes\n",
    "        ax.plot(unit.real, unit.imag, color=\"black\", ls=\"--\", lw=1.0, alpha=0.8)\n",
    "        ax.axhline(0, color=\"#9aa1a6\", lw=0.6)\n",
    "        ax.axvline(0, color=\"#9aa1a6\", lw=0.6)\n",
    "\n",
    "        # Limits, labels\n",
    "        ax.set_xlim(-rlim, rlim); ax.set_ylim(-rlim, rlim)\n",
    "        ax.set_xlabel(\"Re(λ)\"); ax.set_ylabel(\"Im(λ)\")\n",
    "        ax.set_title(name)\n",
    "\n",
    "        # Inset |λ| distribution\n",
    "        if add_hist:\n",
    "            inset = ax.inset_axes([0.60, 0.60, 0.36, 0.36])\n",
    "            sns.histplot(lam_abs, bins=40, stat=\"density\", element=\"step\",\n",
    "                         fill=True, alpha=0.55, ax=inset, color=sns.color_palette(\"mako\", 3)[2])\n",
    "            try:\n",
    "                sns.kdeplot(lam_abs, lw=1.2, ax=inset, color=sns.color_palette(\"mako\", 3)[0])\n",
    "            except Exception:\n",
    "                pass\n",
    "            inset.axvline(1.0, color=\"k\", ls=\"--\", lw=1.0)\n",
    "            inset.set_xlabel(\"|λ|\", fontsize=7)\n",
    "            inset.set_ylabel(\"\")\n",
    "            inset.tick_params(axis=\"both\", labelsize=8)\n",
    "            sns.despine(ax=inset, left=True, bottom=False)\n",
    "\n",
    "        sns.despine(ax=ax)\n",
    "\n",
    "    # Hide unused axes\n",
    "    for j in range(n, nrows * ncols):\n",
    "        r, c = divmod(j, ncols)\n",
    "        axes[r, c].axis(\"off\")\n",
    "\n",
    "    # Global title and colorbar\n",
    "    #if title is None:\n",
    "        #title = f\"Eigen-spectrum (ρ={rho}, seed={seed})\"\n",
    "    fig.suptitle(title, y=1.02)\n",
    "\n",
    "    # Shared colorbar for |λ|\n",
    "    # Create a fake ScalarMappable with global normalization\n",
    "    '''norm = mpl.colors.Normalize(vmin=0, vmax=max_abs)\n",
    "    sm = mpl.cm.ScalarMappable(norm=norm, cmap=cmap_obj)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=axes.ravel().tolist(), fraction=0.018, pad=0.02)\n",
    "    cbar.set_label(\"|λ|\")'''\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save\n",
    "    if save_name is None:\n",
    "        save_name = f\"eigenspectrum_grid_rho{rho}_seed{seed}.png\"\n",
    "    out = FIG_DIR / save_name\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "plot_eigenspectrum_models(BASELINES, TESTING_RES_CLASS, rho=0.95, seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ed235-43c4-41ad-88e2-8e8d98e22ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Participation Ratio utilities & plots =====================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "\n",
    "\n",
    "def _safe_name(s: str) -> str:\n",
    "    return str(s).replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def participation_ratio(X: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Effective dimensionality: (tr Σ)^2 / tr(Σ^2), where Σ is the column covariance.\n",
    "    X shape: [T, D]  (time × dims)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    if X.ndim != 2 or X.shape[0] < 2:\n",
    "        return np.nan\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    C = np.cov(Xc, rowvar=False)  # D×D\n",
    "    tr = float(np.trace(C))\n",
    "    tr2 = float(np.sum(C * C))    # Frobenius norm squared\n",
    "    if tr2 <= 0 or not np.isfinite(tr2):\n",
    "        return np.nan\n",
    "    return (tr * tr) / (tr2 + 1e-12)\n",
    "\n",
    "def pr_timecourse_from_preds(pred: np.ndarray, window: int = 300, step: int = 50):\n",
    "    \"\"\"\n",
    "    Sliding-window PR over predicted outputs (dims in columns).\n",
    "    Returns: (center_indices, PR_values)\n",
    "    \"\"\"\n",
    "    pred = np.asarray(pred, dtype=float)\n",
    "    if pred.ndim == 1:\n",
    "        pred = pred[:, None]\n",
    "    T = len(pred)\n",
    "    if window < 2 or T < window:\n",
    "        # not enough data for one window\n",
    "        return np.array([], dtype=int), np.array([], dtype=float)\n",
    "\n",
    "    vals, centers = [], []\n",
    "    for s in range(0, T - window + 1, step):\n",
    "        Xw = pred[s:s+window]\n",
    "        vals.append(participation_ratio(Xw))\n",
    "        centers.append(s + window // 2)\n",
    "    return np.asarray(centers, dtype=int), np.asarray(vals, dtype=float)\n",
    "\n",
    "def plot_pr_timecourse_mean_ci(pred_store: dict, model: str, scenarios: list,\n",
    "                               window: int = 300, step: int = 50, dpi: int = 300,\n",
    "                               color: str = \"C0\"):\n",
    "    \"\"\"\n",
    "    scenarios: list of keys (Model, Init, Split, Rho, Seed) to average PR over.\n",
    "    Uses predictions only (no ground truth needed).\n",
    "    \"\"\"\n",
    "    if not scenarios:\n",
    "        raise ValueError(\"No scenarios provided.\")\n",
    "\n",
    "    all_t, all_pr = [], []\n",
    "    for key in scenarios:\n",
    "        if key[0] != model:\n",
    "            raise ValueError(f\"Scenario {key} does not match model '{model}'.\")\n",
    "        if key not in pred_store:\n",
    "            # skip missing predictions gracefully\n",
    "            continue\n",
    "        pred = pred_store[key]\n",
    "        t_idx, pr = pr_timecourse_from_preds(pred, window=window, step=step)\n",
    "        if len(pr) == 0:\n",
    "            continue\n",
    "        all_t.append(t_idx)\n",
    "        all_pr.append(pr)\n",
    "\n",
    "    if not all_pr:\n",
    "        raise ValueError(\"No valid PR series (maybe window too large for sequences).\")\n",
    "\n",
    "    # Align by minimum common length\n",
    "    L = min(map(len, all_pr))\n",
    "    all_pr = np.stack([p[:L] for p in all_pr], axis=0)\n",
    "    t_idx = all_t[0][:L]\n",
    "    mean = np.nanmean(all_pr, axis=0)\n",
    "    sd   = np.nanstd(all_pr, axis=0)\n",
    "    n    = all_pr.shape[0]\n",
    "    ci   = 1.96 * sd / np.sqrt(max(n, 1))\n",
    "\n",
    "    plt.figure(figsize=(8.2, 4.4))\n",
    "    plt.plot(t_idx, mean, lw=2.0, color=color, label=\"mean PR\")\n",
    "    plt.fill_between(t_idx, mean - ci, mean + ci, color=color, alpha=0.20, label=\"95% CI\")\n",
    "    plt.xlabel(\"Time index\")\n",
    "    plt.ylabel(\"Participation Ratio\")\n",
    "    plt.title(f\"PR timecourse — {model}  (window={window}, step={step}, n={n})\")\n",
    "    plt.legend(frameon=False)\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / f\"pr_timecourse_{_safe_name(model)}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "def plot_pr_vs_error(df_metrics: pd.DataFrame, pr_dict: dict,\n",
    "                     metric: str = \"NRMSE\", horizon: int = 1000, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Scatter of model-wise mean PR vs performance metric.\n",
    "\n",
    "    df_metrics: DataFrame containing per-scenario metrics with at least a 'Model' column.\n",
    "                If it has a 'Horizon' column, we select rows with Horizon==horizon.\n",
    "    pr_dict   : {(Model, Init, Split, Rho, Seed)->PR} or {Model->PR}. We average by Model.\n",
    "    \"\"\"\n",
    "    # Build PR per model\n",
    "    rows = []\n",
    "    for k, v in pr_dict.items():\n",
    "        mdl = k[0] if isinstance(k, tuple) else k\n",
    "        rows.append({\"Model\": mdl, \"PR\": float(v)})\n",
    "    pr_df = pd.DataFrame(rows)\n",
    "    pr_mean = pr_df.groupby(\"Model\", as_index=True)[\"PR\"].mean()\n",
    "\n",
    "    # Build metric per model\n",
    "    if \"Horizon\" in df_metrics.columns:\n",
    "        met_series = (df_metrics[df_metrics[\"Horizon\"] == horizon]\n",
    "                      .groupby(\"Model\", as_index=True)[metric].mean())\n",
    "    else:\n",
    "        met_series = df_metrics.groupby(\"Model\", as_index=True)[metric].mean()\n",
    "\n",
    "    # Align and drop missing\n",
    "    dfp = pd.concat([pr_mean, met_series], axis=1).dropna()\n",
    "    if dfp.empty:\n",
    "        raise ValueError(\"No overlapping models between PR and metrics.\")\n",
    "\n",
    "    plt.figure(figsize=(6.6, 5.2))\n",
    "    sns.regplot(data=dfp.reset_index(), x=\"PR\", y=metric, scatter_kws=dict(s=60, alpha=0.85))\n",
    "    # annotate points\n",
    "    for _, row in dfp.reset_index().iterrows():\n",
    "        plt.annotate(row[\"Model\"], (row[\"PR\"], row[metric]),\n",
    "                     textcoords=\"offset points\", xytext=(6, 6))\n",
    "    plt.title(f\"Participation Ratio vs {metric}\" + (f\"  (h={horizon})\" if \"Horizon\" in df_metrics.columns else \"\"))\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / f\"pr_vs_{metric}\" / (\"h\" + str(horizon) if \"Horizon\" in df_metrics.columns else \"overall\")\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out = out.with_suffix(\".png\")\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "# choose scenarios for one model \n",
    "scens = [k for k in pred_store if k[0] == \"Cycle\"  and k[2] == 0.8 and k[3] == 0.95]\n",
    "plot_pr_timecourse_mean_ci(pred_store, \"Cycle\",   scens, window=300, step=50)\n",
    "\n",
    "scens = [k for k in pred_store if k[0] == \"CHORD-ESN\" and k[2] == 0.8 and k[3] == 0.95]\n",
    "plot_pr_timecourse_mean_ci(pred_store, \"CHORD-ESN\", scens, window=300, step=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92b13e-76f2-4542-8e81-79e67c79f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== PR vs NRMSE@1000 (no truth recomputation) ===================\n",
    "\n",
    "H = 1000  # target horizon\n",
    "\n",
    "# 1) One-number PR per scenario (whole prediction window)\n",
    "pr_per_scen = {\n",
    "    k: participation_ratio(pred_store[k])\n",
    "    for k in pred_store.keys()\n",
    "}\n",
    "\n",
    "# 2) Build per-scenario NRMSE@1000 using ORIGINAL test_y from DATA cache\n",
    "rows = []\n",
    "skipped = 0\n",
    "for k, pred in pred_store.items():\n",
    "    # key format: (Model, Init, Split, Rho, Seed)\n",
    "    model, init_id, split, rho, seed = k\n",
    "\n",
    "    # fetch ORIGINAL test target from cache\n",
    "    if 'DATA' not in globals() or (init_id, split) not in DATA:\n",
    "        raise RuntimeError(\n",
    "            f\"DATA cache missing for (init={init_id}, split={split}). \"\n",
    "            \"Please build DATA[(init, split)] with {'test_y', 'time_test', ...}.\"\n",
    "        )\n",
    "    y_true = DATA[(init_id, split)][\"test_y\"]\n",
    "\n",
    "    # ensure equal length & enough samples for the requested horizon\n",
    "    T = min(len(pred), len(y_true))\n",
    "    if T < H:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # compute NRMSE at horizon H using your existing helper\n",
    "    nrmse_at_H = evaluate_nrmse(pred[:H], y_true[:H], [H])[H]\n",
    "    rows.append({\"Model\": model, \"Horizon\": H, \"NRMSE\": nrmse_at_H})\n",
    "\n",
    "if skipped:\n",
    "    print(f\"Note: skipped {skipped} scenario(s) with fewer than {H} steps.\")\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "\n",
    "# 3) Plot PR (per-scenario) vs NRMSE@1000 (aggregated to per-model inside the helper)\n",
    "plot_pr_vs_error(df_metrics, pr_per_scen, metric=\"NRMSE\", horizon=H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0569e1-b272-4f2d-853c-4844e5358c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "def _safe(s): return s.replace(\" \", \"\").replace(\"/\", \"_\")\n",
    "\n",
    "def _extract_peaks(sig, distance=20, prominence=None):\n",
    "    \"\"\"Return peak values in order.\"\"\"\n",
    "    idx, _ = find_peaks(sig, distance=distance, prominence=prominence)\n",
    "    return sig[idx]\n",
    "\n",
    "def plot_return_map_per_model(pred_store, DATA, model, init_id, split, rho, seed,\n",
    "                              component=0, distance=20, prominence=None,\n",
    "                              dpi=300):\n",
    "    \"\"\"Return map: peak_{n+1} vs peak_n for truth & model (chosen component).\"\"\"\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "    y_true = DATA[(init_id, split)][\"test_y\"]\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    y_true, y_pred = y_true[:T], y_pred[:T]\n",
    "\n",
    "    # peaks\n",
    "    pt = _extract_peaks(y_true[:, component], distance=distance, prominence=prominence)\n",
    "    pp = _extract_peaks(y_pred[:, component], distance=distance, prominence=prominence)\n",
    "\n",
    "    # build x_n -> x_{n+1}\n",
    "    def _pairs(v):\n",
    "        return v[:-1], v[1:] if len(v) > 1 else (np.array([]), np.array([]))\n",
    "    xt, yt = _pairs(pt)\n",
    "    xp, yp = _pairs(pp)\n",
    "\n",
    "    comp_name = [\"x\", \"y\", \"z\"][component]\n",
    "    plt.figure(figsize=(6.2, 5.8))\n",
    "    sns.scatterplot(x=xt, y=yt, s=28, color=TRUTH_COLOR, label=\"Truth\", alpha=0.7, edgecolor=None)\n",
    "    sns.scatterplot(x=xp, y=yp, s=28, color=PALETTE.get(model, \"C0\"), label=model, alpha=0.7, edgecolor=None)\n",
    "\n",
    "    # y=x reference & limits\n",
    "    lo = min(xt.min() if len(xt) else 0, xp.min() if len(xp) else 0,\n",
    "             yt.min() if len(yt) else 0, yp.min() if len(yp) else 0)\n",
    "    hi = max(xt.max() if len(xt) else 1, xp.max() if len(xp) else 1,\n",
    "             yt.max() if len(yt) else 1, yp.max() if len(yp) else 1)\n",
    "    plt.plot([lo, hi], [lo, hi], ls=\":\", color=\"#666\", lw=1.2)\n",
    "    plt.xlabel(f\"Peak {comp_name}_n\"); plt.ylabel(f\"Peak {comp_name}_{{n+1}}\")\n",
    "    plt.title(f\"Return map ({comp_name}) — {model}\\ninit={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.legend(frameon=False); plt.tight_layout()\n",
    "    out = FIG_DIR / f\"returnmap_{_safe(model)}_{comp_name}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "plot_return_map_per_model(pred_store, DATA, \"CHORD-ESN\", init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "                          component=0, distance=30, prominence=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793b021-2577-4055-8d28-75fb54de7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _phase(sig):\n",
    "    \"\"\"Analytic phase in radians, unwrapped.\"\"\"\n",
    "    a = hilbert(sig - np.mean(sig))\n",
    "    return np.unwrap(np.angle(a))\n",
    "\n",
    "def plot_phase_drift_per_model(pred_store, DATA, model, init_id, split, rho, seed,\n",
    "                               component=0, max_len=None, bins=24, dpi=300):\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "    y_true = DATA[(init_id, split)][\"test_y\"]\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    if max_len is not None: T = min(T, max_len)\n",
    "    y_true, y_pred = y_true[:T, component], y_pred[:T, component]\n",
    "\n",
    "    φ_true = _phase(y_true)\n",
    "    φ_pred = _phase(y_pred)\n",
    "    Δφ = np.mod(φ_pred - φ_true + np.pi, 2*np.pi) - np.pi  # wrap to (-π, π)\n",
    "\n",
    "    t = DATA[(init_id, split)][\"time_test\"][:T]\n",
    "\n",
    "    # layout: time series (top) + rose histogram (bottom)\n",
    "    fig = plt.figure(figsize=(10, 6.4))\n",
    "    gs = fig.add_gridspec(2, 2, height_ratios=[2.0, 1.2])\n",
    "    ax0 = fig.add_subplot(gs[0, :])\n",
    "    ax1 = fig.add_subplot(gs[1, 0], projection='polar')\n",
    "    ax2 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    # phase drift time-course\n",
    "    ax0.plot(t, Δφ, color=PALETTE.get(model, \"C0\"), lw=1.6)\n",
    "    ax0.axhline(0, color=TRUTH_COLOR, ls=\":\", lw=1.2)\n",
    "    ax0.set_ylabel(\"Phase drift Δφ (rad)\"); ax0.set_xlabel(\"Time (s)\")\n",
    "    ax0.set_title(f\"Instantaneous phase drift — {model} (component {['x','y','z'][component]})\")\n",
    "\n",
    "    # rose histogram\n",
    "    theta = Δφ % (2*np.pi)\n",
    "    ax1.hist(theta, bins=bins, density=True)\n",
    "    ax1.set_title(\"Phase drift rose\")\n",
    "\n",
    "    # KDE of phase drift\n",
    "    sns.kdeplot(x=Δφ, fill=True, ax=ax2, color=PALETTE.get(model, \"C0\"))\n",
    "    ax2.axvline(0, color=TRUTH_COLOR, ls=\":\", lw=1.2)\n",
    "    ax2.set_xlabel(\"Phase drift Δφ (rad)\"); ax2.set_ylabel(\"Density\")\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / f\"phase_drift_{_safe(model)}_{['x','y','z'][component]}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "plot_phase_drift_per_model(pred_store, DATA, \"CHORD-ESN\", init_id=1, split=0.8, rho=0.95, seed=1, component=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbedf4c-4483-438b-8023-d65c3ed64152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_colored_attractor(pred_store, DATA, model, init_id, split, rho, seed,\n",
    "                                 max_points=8000, cmap=\"rocket\", dpi=300):\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No predictions for {key}\")\n",
    "    Yp = pred_store[key]\n",
    "    Yt = DATA[(init_id, split)][\"test_y\"]\n",
    "    T = min(len(Yp), len(Yt))\n",
    "    Yp, Yt = Yp[:T], Yt[:T]\n",
    "\n",
    "    err = np.linalg.norm(Yp - Yt, axis=1)  # pointwise 3D error\n",
    "    # downsample evenly to keep picture crisp\n",
    "    if T > max_points:\n",
    "        idx = np.linspace(0, T-1, max_points).astype(int)\n",
    "        Yt, err = Yt[idx], err[idx]\n",
    "\n",
    "    fig = plt.figure(figsize=(8.4, 6.8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    sc = ax.scatter(Yt[:,0], Yt[:,1], Yt[:,2], c=err, cmap=cmap, s=6, alpha=0.9)\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\"); ax.set_zlabel(\"z\")\n",
    "    cb = plt.colorbar(sc, pad=0.05, shrink=0.8)\n",
    "    cb.set_label(r\"$\\| \\hat{y}_t - y_t \\|$\")\n",
    "    ax.set_title(f\"Error-colored truth trajectory — {model}\\ninit={init_id}, split={split}, ρ={rho}, seed={seed}\")\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / f\"err_colored_attractor_{_safe(model)}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "plot_error_colored_attractor(pred_store, DATA, \"Deep\", init_id=1, split=0.8, rho=0.95, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434238d8-b227-4325-adbc-9a6190840ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FTLE map • Shadowing-time survival • OT pushforward\n",
    "# ============================================\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.2)\n",
    "\n",
    "\n",
    "# Palette helper\n",
    "def _palette_from_pred_store(pred_store, palette=\"tab10\"):\n",
    "    models = sorted({k[0] for k in pred_store.keys()})\n",
    "    pal = sns.color_palette(palette, n_colors=len(models))\n",
    "    return {m: pal[i] for i, m in enumerate(models)}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) FTLE map along the true trajectory (per-model figure)\n",
    "# ------------------------------------------------------------\n",
    "def plot_ftle_map(DATA, pred_store, model, init_id, split, rho, seed,\n",
    "                  tau_steps=40, theiler=50, max_len=5000,\n",
    "                  cmap=\"magma\", truth_color=\"#3b3b3b\", dpi=300):\n",
    "    \"\"\"\n",
    "    Colors the TRUE 3D trajectory by local FTLE, computed via nearest-neighbor\n",
    "    separation over a horizon of 'tau_steps' while skipping a Theiler window.\n",
    "    Also overlays instantaneous error ‖ŷ - y‖ over time.\n",
    "    \"\"\"\n",
    "    # --- fetch truth + time\n",
    "    y_true = DATA[(init_id, split)][\"test_y\"]\n",
    "    t      = DATA[(init_id, split)][\"time_test\"]\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No preds for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    # align\n",
    "    T = min(len(t), len(y_true), len(y_pred))\n",
    "    t = t[:T]; y_true = y_true[:T]; y_pred = y_pred[:T]\n",
    "\n",
    "    if max_len is not None:\n",
    "        T = min(T, max_len)\n",
    "        t = t[:T]; y_true = y_true[:T]; y_pred = y_pred[:T]\n",
    "\n",
    "    dt = float(np.mean(np.diff(t))) if len(t) > 1 else 1.0\n",
    "    if T <= tau_steps + 2:\n",
    "        raise ValueError(\"Sequence too short for given tau_steps.\")\n",
    "\n",
    "    # --- FTLE via nearest neighbor with Theiler window\n",
    "    eps = 1e-12\n",
    "    ftle = np.full(T, np.nan, dtype=float)\n",
    "    tree = cKDTree(y_true[:-tau_steps])  # neighbors only where j+tau valid\n",
    "\n",
    "    for i in range(T - tau_steps):\n",
    "        # query a few neighbors; pick first outside Theiler window\n",
    "        dists, idxs = tree.query(y_true[i], k=min(15, T - tau_steps))\n",
    "        if np.isscalar(idxs):\n",
    "            idxs = np.array([idxs])\n",
    "            dists = np.array([dists])\n",
    "        j = None\n",
    "        for cand in idxs:\n",
    "            if abs(cand - i) > theiler:\n",
    "                j = int(cand); break\n",
    "        if j is None:\n",
    "            continue\n",
    "        d0 = norm(y_true[i] - y_true[j]) + eps\n",
    "        d1 = norm(y_true[i + tau_steps] - y_true[j + tau_steps]) + eps\n",
    "        ftle[i] = (1.0 / (tau_steps * dt)) * np.log(d1 / d0)\n",
    "\n",
    "    # robust color scaling\n",
    "    vmin = np.nanpercentile(ftle, 5)\n",
    "    vmax = np.nanpercentile(ftle, 95)\n",
    "    if not np.isfinite(vmin) or not np.isfinite(vmax) or vmin == vmax:\n",
    "        vmin, vmax = np.nanmin(ftle), np.nanmax(ftle)\n",
    "\n",
    "    # error norm\n",
    "    err = norm(y_pred - y_true, axis=1)\n",
    "\n",
    "    # --- figure: left 3D colored by FTLE, right error over time\n",
    "    fig = plt.figure(figsize=(12, 5.6))\n",
    "    gs = GridSpec(1, 2, width_ratios=[1.2, 1.0], figure=fig)\n",
    "    ax3d = fig.add_subplot(gs[0, 0], projection=\"3d\")\n",
    "\n",
    "    # Use scatter with FTLE color\n",
    "    cvals = ftle\n",
    "    sc = ax3d.scatter(y_true[:,0], y_true[:,1], y_true[:,2],\n",
    "                      c=cvals, cmap=cmap, s=4, linewidths=0, vmin=vmin, vmax=vmax)\n",
    "    ax3d.set_xlabel(\"x\"); ax3d.set_ylabel(\"y\"); ax3d.set_zlabel(\"z\")\n",
    "    ax3d.set_title(\"True phase trajectory colored by FTLE\")\n",
    "    cb = fig.colorbar(sc, ax=ax3d, fraction=0.046, pad=0.04)\n",
    "    cb.set_label(\"FTLE (1/s)\")\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    ax.plot(t, err, lw=1.4, color=\"#1f77b4\")\n",
    "    ax.set_xlabel(\"Time (s)\"); ax.set_ylabel(\"‖ŷ − y‖\")\n",
    "    ax.set_title(f\"Instantaneous error — {model}\")\n",
    "    ax.grid(alpha=0.25)\n",
    "\n",
    "    plt.suptitle(f\"FTLE map & error | model={model}  init={init_id}  split={split}  ρ={rho}  seed={seed}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.95])\n",
    "\n",
    "    out = FIG_DIR / f\"ftle_map_{model.replace(' ','')}_init{init_id}_split{split}_rho{rho}_seed{seed}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Shadowing-time survival curves (Kaplan–Meier style)\n",
    "# ------------------------------------------------------------\n",
    "def _km_from_times(times):\n",
    "    \"\"\"\n",
    "    Given list/array of positive times (shadowing durations), return step points (x, S(x)).\n",
    "    S(t) = P(T >= t). Censoring not handled; assumes full observations.\n",
    "    \"\"\"\n",
    "    times = np.asarray(times, float)\n",
    "    times = times[np.isfinite(times) & (times >= 0)]\n",
    "    if times.size == 0:\n",
    "        return np.array([0.0]), np.array([1.0])\n",
    "    ts = np.sort(times)\n",
    "    n = len(ts)\n",
    "    xs = np.r_[0.0, ts]\n",
    "    # S jumps down at each observed time (no ties handled separately—fine visually)\n",
    "    S = [1.0]\n",
    "    remaining = n\n",
    "    last = 0.0\n",
    "    for t in ts:\n",
    "        remaining -= 1\n",
    "        S.append(remaining / n)\n",
    "        last = t\n",
    "    return xs, np.array(S)\n",
    "\n",
    "def plot_shadowing_survival(pred_store, DATA, models=None, splits=None, rhos=None, seeds=None,\n",
    "                            threshold=0.4, lambda_max=None, palette=\"tab10\",\n",
    "                            title=\"Shadowing-time survival (Kaplan–Meier style)\",\n",
    "                            dpi=300):\n",
    "    \"\"\"\n",
    "    Build survival curves S(t) = P(VPT >= t). Uses your compute_valid_prediction_time().\n",
    "    Filters by model/split/rho/seed if provided.\n",
    "    \"\"\"\n",
    "    # try to grab lambda_max from your global map if not supplied\n",
    "    if lambda_max is None:\n",
    "        try:\n",
    "            lambda_max = LAMBDA_MAP.get(SYSTEM.lower(), 0.9)\n",
    "        except Exception:\n",
    "            lambda_max = 0.9\n",
    "\n",
    "    # selection\n",
    "    keys = list(pred_store.keys())\n",
    "    if models is not None:\n",
    "        keys = [k for k in keys if k[0] in set(models)]\n",
    "    if splits is not None:\n",
    "        keys = [k for k in keys if k[2] in set(splits)]\n",
    "    if rhos is not None:\n",
    "        keys = [k for k in keys if k[3] in set(rhos)]\n",
    "    if seeds is not None:\n",
    "        keys = [k for k in keys if k[4] in set(seeds)]\n",
    "\n",
    "    if len(keys) == 0:\n",
    "        raise ValueError(\"No matching scenarios in pred_store with given filters.\")\n",
    "\n",
    "    model_list = sorted({k[0] for k in keys})\n",
    "    palmap = {m: c for m, c in zip(model_list, sns.color_palette(palette, n_colors=len(model_list)))}\n",
    "\n",
    "    # compute VPT per scenario\n",
    "    vpts = {m: [] for m in model_list}\n",
    "    for (model, init_id, split, rho, seed) in keys:\n",
    "        y_true = DATA[(init_id, split)][\"test_y\"]\n",
    "        t      = DATA[(init_id, split)][\"time_test\"]\n",
    "        pred   = pred_store[(model, init_id, split, rho, seed)]\n",
    "        T = min(len(t), len(y_true), len(pred))\n",
    "        y_true = y_true[:T]; pred = pred[:T]; t = t[:T]\n",
    "        try:\n",
    "            T_VPT, T_lambda, _ = compute_valid_prediction_time(\n",
    "                y_true, pred, t, threshold=threshold, lambda_max=lambda_max\n",
    "            )\n",
    "            vpts[model].append(float(T_VPT))\n",
    "        except Exception:\n",
    "            # fall back: first time error exceeds threshold (absolute norm)\n",
    "            err = norm(pred - y_true, axis=1)\n",
    "            idx = np.argmax(err > threshold)\n",
    "            tv = t[idx] if (err > threshold).any() else t[-1]\n",
    "            vpts[model].append(float(tv))\n",
    "\n",
    "    # plot survival curves\n",
    "    plt.figure(figsize=(8.8, 5.2))\n",
    "    for m in model_list:\n",
    "        xs, S = _km_from_times(vpts[m])\n",
    "        plt.step(xs, S, where=\"post\", color=palmap[m], lw=2, label=f\"{m} (median≈{np.nanmedian(vpts[m]):.2f}s)\")\n",
    "    plt.ylim(0, 1.02)\n",
    "    plt.xlabel(\"Time (s)\"); plt.ylabel(\"Survival S(t) = P(VPT ≥ t)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.legend(frameon=False, ncol=2)\n",
    "    out = FIG_DIR / \"survival_shadowing_curves.png\"\n",
    "    plt.tight_layout(); plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Optimal-transport “pushforward” (2D plane) via Sinkhorn\n",
    "# ------------------------------------------------------------\n",
    "def _hist2d_with_centers(X, dims=(0,1), bins=40, ranges=None):\n",
    "    if isinstance(bins, int): bins = (bins, bins)\n",
    "    x = X[:, dims[0]]; y = X[:, dims[1]]\n",
    "    if ranges is None:\n",
    "        xr = (x.min(), x.max()); yr = (y.min(), y.max())\n",
    "    else:\n",
    "        xr, yr = ranges\n",
    "    H, xedges, yedges = np.histogram2d(x, y, bins=bins, range=[xr, yr])\n",
    "    # centers\n",
    "    xc = 0.5*(xedges[:-1] + xedges[1:])\n",
    "    yc = 0.5*(yedges[:-1] + yedges[1:])\n",
    "    Xc, Yc = np.meshgrid(xc, yc, indexing=\"ij\")\n",
    "    centers = np.stack([Xc.ravel(), Yc.ravel()], axis=1)  # (n_cells, 2)\n",
    "    return H, centers, (xr, yr)\n",
    "\n",
    "def _sinkhorn(a, b, C, reg=0.05, n_iter=200, tol=1e-9):\n",
    "    \"\"\"\n",
    "    Simple entropic Sinkhorn on CPU.\n",
    "    a, b: nonnegative, sum to 1, shape (n,), (m,)\n",
    "    C: cost matrix (n, m)\n",
    "    reg: regularization strength (smaller = closer to true OT, slower/stiffer)\n",
    "    Returns transport plan P (n, m).\n",
    "    \"\"\"\n",
    "    K = np.exp(-C / reg)\n",
    "    u = np.ones_like(a) / a.size\n",
    "    v = np.ones_like(b) / b.size\n",
    "    eps = 1e-16\n",
    "    for it in range(n_iter):\n",
    "        u_prev = u\n",
    "        Kv = K @ v + eps\n",
    "        u = a / Kv\n",
    "        Ku = K.T @ u + eps\n",
    "        v = b / Ku\n",
    "        if it % 10 == 0 and np.linalg.norm(u - u_prev, 1) < tol:\n",
    "            break\n",
    "    P = (u[:, None] * K) * v[None, :]\n",
    "    return P\n",
    "\n",
    "def plot_ot_pushforward(DATA, pred_store, model, init_id, split, rho, seed,\n",
    "                        dims=(0,1), bins=40, reg=0.05,\n",
    "                        n_vectors=250, min_mass=1e-4, max_len=None,\n",
    "                        cmap_truth=\"Blues\", cmap_pred=\"Oranges\", dpi=300):\n",
    "    \"\"\"\n",
    "    2D plane (dims) OT between truth and prediction histograms on same grid.\n",
    "    Left: truth density; middle: pred density; right: pushforward vectors\n",
    "    (mass-weighted displacement of each source cell).\n",
    "    \"\"\"\n",
    "    y_true = DATA[(init_id, split)][\"test_y\"]\n",
    "    key = (model, init_id, split, rho, seed)\n",
    "    if key not in pred_store:\n",
    "        raise ValueError(f\"No preds for {key}\")\n",
    "    y_pred = pred_store[key]\n",
    "\n",
    "    T = min(len(y_true), len(y_pred))\n",
    "    if max_len is not None: T = min(T, max_len)\n",
    "    y_true = y_true[:T]; y_pred = y_pred[:T]\n",
    "\n",
    "    # shared ranges for fairness\n",
    "    mins = np.minimum(y_true.min(axis=0), y_pred.min(axis=0))\n",
    "    maxs = np.maximum(y_true.max(axis=0), y_pred.max(axis=0))\n",
    "    ranges = [(mins[dims[0]], maxs[dims[0]]),\n",
    "              (mins[dims[1]], maxs[dims[1]])]\n",
    "\n",
    "    Ht, centers, _ = _hist2d_with_centers(y_true, dims=dims, bins=bins, ranges=ranges)\n",
    "    Hp, _, _        = _hist2d_with_centers(y_pred, dims=dims, bins=bins, ranges=ranges)\n",
    "\n",
    "    a = Ht.ravel().astype(float); b = Hp.ravel().astype(float)\n",
    "    sa, sb = a.sum(), b.sum()\n",
    "    if sa == 0 or sb == 0:\n",
    "        raise ValueError(\"Empty histograms; cannot compute OT.\")\n",
    "    a /= sa; b /= sb\n",
    "\n",
    "    # cost matrix (squared Euclidean)\n",
    "    C = distance.cdist(centers, centers, metric=\"sqeuclidean\")\n",
    "    P = _sinkhorn(a, b, C, reg=reg, n_iter=300)\n",
    "\n",
    "    # W2 distance (with squared cost)\n",
    "    W2_sq = np.sum(P * C)\n",
    "    W2 = np.sqrt(max(W2_sq, 0.0))\n",
    "\n",
    "    # Pushforward vectors: expected destination for each source cell\n",
    "    # skip tiny-mass cells to declutter\n",
    "    mask = a > min_mass\n",
    "    a_pos = a[mask]\n",
    "    centers_src = centers[mask]\n",
    "    P_sub = P[mask, :]                        # (#src, n_cells)\n",
    "    dest_mean = (P_sub @ centers) / a_pos[:, None]  # (#src, 2)\n",
    "    disp = dest_mean - centers_src            # displacement vectors\n",
    "\n",
    "    # ranking vectors by mass*length\n",
    "    lengths = np.linalg.norm(disp, axis=1)\n",
    "    score = a_pos * lengths\n",
    "    keep = min(n_vectors, len(score))\n",
    "    if keep > 0:\n",
    "        idx = np.argsort(score)[-keep:]\n",
    "        centers_k = centers_src[idx]\n",
    "        disp_k = disp[idx]\n",
    "    else:\n",
    "        centers_k = centers_src\n",
    "        disp_k = disp\n",
    "\n",
    "    # --- plot densities + pushforward field ---\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4.2))\n",
    "\n",
    "    sns.heatmap(Ht.T, ax=axes[0], cmap=cmap_truth, cbar=True, square=True)\n",
    "    axes[0].set_title(\"Truth density\"); axes[0].set_xlabel(\"bin x\"); axes[0].set_ylabel(\"bin y\")\n",
    "\n",
    "    sns.heatmap(Hp.T, ax=axes[1], cmap=cmap_pred, cbar=True, square=True)\n",
    "    axes[1].set_title(\"Prediction density\"); axes[1].set_xlabel(\"bin x\"); axes[1].set_ylabel(\"bin y\")\n",
    "\n",
    "    ax = axes[2]\n",
    "    sns.heatmap(Ht.T, ax=ax, cmap=cmap_truth, cbar=False, alpha=0.25, square=True)\n",
    "    # normalize to bin coordinates (i,j) for quiver\n",
    "    nx, ny = (Ht.shape[0], Ht.shape[1])\n",
    "    # map centers to grid indices by inverting mesh\n",
    "    # We can reuse integer grid with spacing 1:\n",
    "    # Build pseudo-grid: centers already on uniform grid; reconstruct grid index by rank\n",
    "    # Simpler: rescale centers to [0, nx-1]×[0, ny-1] for arrows\n",
    "    cx = centers_k[:,0]; cy = centers_k[:,1]\n",
    "    # Use original centers of full grid:\n",
    "    all_x = np.unique(centers[:,0]); all_y = np.unique(centers[:,1])\n",
    "    ix = np.searchsorted(all_x, cx)\n",
    "    iy = np.searchsorted(all_y, cy)\n",
    "    tx = dest_mean[idx][:,0]; ty = dest_mean[idx][:,1]\n",
    "    ixt = np.searchsorted(all_x, tx)\n",
    "    iyt = np.searchsorted(all_y, ty)\n",
    "\n",
    "    ax.quiver(ix, iy, (ixt - ix), (iyt - iy),\n",
    "              angles='xy', scale_units='xy', scale=1.0,\n",
    "              color=\"#d62728\", width=0.005, alpha=0.9)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(\"OT pushforward (barycentric)\")\n",
    "    ax.set_xlabel(\"bin x\"); ax.set_ylabel(\"bin y\")\n",
    "\n",
    "    plt.suptitle(f\"Optimal transport pushforward — {model}  |  dims={dims}  W₂≈{W2:.3f}\")\n",
    "    plt.tight_layout(rect=[0,0,1,0.94])\n",
    "\n",
    "    out = FIG_DIR / f\"ot_pushforward_{model.replace(' ','')}_init{init_id}_split{split}_rho{rho}_seed{seed}_d{dims[0]}{dims[1]}.png\"\n",
    "    plt.savefig(out, dpi=dpi, bbox_inches=\"tight\"); plt.show()\n",
    "    print(f\"Saved: {out}\")\n",
    "\n",
    "\n",
    "\n",
    "# 1) FTLE map for one scenario/model\n",
    "plot_ftle_map(DATA, pred_store, model=\"CHORD-ESN\", init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "               tau_steps=40, theiler=50, max_len=4000)\n",
    "\n",
    "# 2) Shadowing-time survival curves for a subset (all models by default)\n",
    "plot_shadowing_survival(pred_store, DATA, models=None, splits=[0.8], rhos=[0.95],\n",
    "                         threshold=0.4, lambda_max=None)\n",
    "\n",
    "# 4) OT pushforward on x–y plane\n",
    "plot_ot_pushforward(DATA, pred_store, model=\"CHORD-ESN\", init_id=1, split=0.8, rho=0.95, seed=1,\n",
    "                     dims=(0,1), bins=40, reg=0.05, n_vectors=300, max_len=4000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9609983-6e99-4d91-aea0-cc56b5d2d910",
   "metadata": {},
   "source": [
    "# Real-World Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe699080-ef9f-43ad-b2c5-18d379a5cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wfdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954789d-b8c2-4191-9f93-fd95636b8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Download and load record and annotations for patient #100\n",
    "record = wfdb.rdrecord('100', sampfrom=0, sampto=25002, pn_dir='mitdb')  # first 20,000 samples\n",
    "annotation = wfdb.rdann('100', 'atr', sampfrom=0, sampto=25002, pn_dir='mitdb')\n",
    "\n",
    "# Get input signal u(t) from the first channel\n",
    "u = record.p_signal[:, 0]\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80021dc-4e40-4da4-a786-efc6ae0b6908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9555a7b8-21aa-4ce7-a398-93ab7021d4ee",
   "metadata": {},
   "source": [
    "## MIT-BIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372e546-8b19-401b-8658-4aa3a884b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "u_min = np.min(u)\n",
    "u_max = np.max(u)\n",
    "u_norm = (u - u_min) / (u_max - u_min)\n",
    "\n",
    "fs = record.fs  # sampling frequency (should be 360 Hz)\n",
    "t_vals = np.arange(len(u_norm)) / fs\n",
    "\n",
    "emb_dim = 3\n",
    "# inputs = u_norm\n",
    "\n",
    "def create_delay_embedding(signal, embed_dim):\n",
    "    L = len(signal) - embed_dim + 1\n",
    "    emb = np.zeros((L, embed_dim))\n",
    "    for i in range(L):\n",
    "        emb[i, :] = signal[i:i+embed_dim]\n",
    "    return emb\n",
    "    \n",
    "inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "\n",
    "# Create target array (heartbeat locations)\n",
    "targets = np.zeros(len(u_norm))\n",
    "targets[annotation.sample] = 1  # mark annotations as 1 (heartbeat)\n",
    "targets = create_delay_embedding(targets, emb_dim)\n",
    "\n",
    "data_size = len(inputs)\n",
    "train_size = 15000\n",
    "train_input = inputs[:train_size]\n",
    "train_target = targets[:train_size]\n",
    "test_input = inputs[train_size+1:]\n",
    "test_target = targets[train_size+1:]\n",
    "test_size = len(test_input)\n",
    "print(f\"Total samples: {data_size}, train size: {train_size}, test size: {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52685b-1e7b-4314-bbd0-3d6e763b143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "VPT_dict = defaultdict(list)\n",
    "VPT_ratio_dict = defaultdict(list)\n",
    "adev_dict = defaultdict(list)\n",
    "\n",
    "all_horizons = [300, 600, 1000]\n",
    "\n",
    "seeds = range(995, 1000)\n",
    "\n",
    "# ===============================\n",
    "# ESN\n",
    "# ===============================\n",
    "for seed in seeds:\n",
    "    esn = SparseESN3D(\n",
    "        reservoir_size=400,\n",
    "        spectral_radius=0.99,\n",
    "        connectivity=0.05,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    esn.fit_readout(train_input, train_target, discard=5000)\n",
    "    esn_preds = esn.predict_open_loop(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Cycle Reservoir\n",
    "# ===============================\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=400,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=5000)\n",
    "    cycle_res_preds = cycle_res.predict_open_loop(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# CRJ Reservoir\n",
    "# ===============================\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=400,\n",
    "        edge_weight=0.80,\n",
    "        jump=10,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=5000)\n",
    "    crj_preds = crj.predict_open_loop(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Small-World Reservoir\n",
    "# ===============================\n",
    "for seed in seeds:\n",
    "    sw = SWRes3D_IO(\n",
    "        reservoir_size=400,\n",
    "        rewiring_prob=0.10,\n",
    "        degree=6,\n",
    "        spectral_radius=0.99,\n",
    "        gain=1.30,\n",
    "        input_scale=0.20,\n",
    "        leaking_rate=0.20,\n",
    "        ridge_alpha=1e-6,\n",
    "        num_input_nodes=12,\n",
    "        num_output_nodes=12,\n",
    "        io_separation_mode=\"max\",\n",
    "        seed=seed\n",
    "    )\n",
    "    sw.fit_readout(train_input, train_target, discard=5000)\n",
    "    sw_preds = sw.predict_open_loop(test_input)\n",
    "    sw_nrmse = evaluate_nrmse(sw_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SW'].append(sw_nrmse)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Deep-ESN\n",
    "# ===============================\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=3,\n",
    "        input_dim=3,\n",
    "        reservoir_size=100,  # smaller reservoir size\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=5000)\n",
    "    deepesn_preds = deepesn.predict_open_loop(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5cecef-fb5e-4f18-9ac4-cd4aa41ae83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    chord = CHORDESN(\n",
    "        num_nodes         = 400,\n",
    "        input_dim         = 3,\n",
    "        edges             = None,\n",
    "        faces             = None,\n",
    "        avg_degree        = 9,\n",
    "        star0_diag        = None,\n",
    "        star1_diag        = None,\n",
    "        star2_diag        = None,\n",
    "        lam_node          = 0.51,\n",
    "        lam_edge          = 0.33,\n",
    "        lam_face          = 0.69,\n",
    "        leak_exact        = 0.20,\n",
    "        leak_coexact      = 0.20,\n",
    "        leak_harm         = 0.06,\n",
    "        heat0             = 0.06,\n",
    "        heat1             = 0.01,\n",
    "        heat2             = 0.02,\n",
    "        alpha             = 0.41,\n",
    "        beta              = 0.22,\n",
    "        gamma             = 0.37,\n",
    "        node_mix_gain     = 0.67,\n",
    "        edge_mix_gain     = 0.45,\n",
    "        face_mix_gain     = 0.44,\n",
    "        input_scale_node  = 0.15,\n",
    "        input_scale_edge  = 0.21,\n",
    "        input_scale_face  = 0.12,\n",
    "        projector_eps     = 0.000615,\n",
    "        cg_tol            = 0.000624,\n",
    "        cg_maxiter        = 100,\n",
    "        proj_every        = 1,\n",
    "        ridge_alpha       = 0.000008,\n",
    "        use_poly          = True,\n",
    "        feature_mode      = \"node_harm\",\n",
    "        seed              = seed,\n",
    "    )\n",
    "    chord.fit_readout(train_input, train_target, discard=100)\n",
    "    chord_preds = chord.predict_open_loop(test_input)\n",
    "    chord_nrmse = evaluate_nrmse(chord_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CHORD'].append(chord_nrmse)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39502775-f9f4-49ac-b84d-c9586e110191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23501e1-33da-4b6d-9ffa-1f37f452e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'SW':<17} {'DeepESN':<17} {'CHORD':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    sw_vals = [np.mean(sw_nrmse[horizon]) for sw_nrmse in nrmse_dict['SW']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    chord_vals = [np.mean(chord_nrmse[horizon]) for chord_nrmse in nrmse_dict['CHORD']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, sw_vals, deep_vals, chord_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a550f28-cd93-4559-9275-4cb2aedf2c67",
   "metadata": {},
   "source": [
    "## Sunspot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f19ff-6d90-4349-a000-7d5b7c4ed70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path(\"..\") / \"datasets\" / \"SN_m_tot_V2.0.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b9f58-00ea-4db8-a0a5-9651bd5d651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:, 3].values\n",
    "dt = 1\n",
    "dataset_size = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 2000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}\\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd007bd8-3e18-4015-9f84-94b46f7d158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d6ff4-ec58-4acb-accf-8dc5a54ff601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "VPT_dict = defaultdict(list)\n",
    "VPT_ratio_dict = defaultdict(list)\n",
    "adev_dict = defaultdict(list)\n",
    "\n",
    "all_horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1000)\n",
    "\n",
    "for seed in seeds:\n",
    "    esn = SparseESN3D(\n",
    "        reservoir_size=400, spectral_radius=0.99, connectivity=0.05,\n",
    "        input_scale=0.2, leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4, seed=seed)\n",
    "    esn.fit_readout(train_input, train_target, discard=100)\n",
    "    esn_preds = esn.predict_open_loop(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=400,\n",
    "        #cycle_weight = 0.8,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=100)\n",
    "    cycle_res_preds = cycle_res.predict_open_loop(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=400,\n",
    "        edge_weight=0.8,\n",
    "        jump=15,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=100)\n",
    "    crj_preds = crj.predict_open_loop(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "for seed in seeds:\n",
    "    sw = SWRes3D_IO(\n",
    "        reservoir_size=400, rewiring_prob=0.10, degree=6,\n",
    "        spectral_radius=0.99, gain=1.30, input_scale=0.20,\n",
    "        leaking_rate=0.20, ridge_alpha=1e-6,\n",
    "        num_input_nodes=12, num_output_nodes=12,\n",
    "        io_separation_mode=\"max\", seed=seed)\n",
    "    \n",
    "    sw.fit_readout(train_input, train_target, discard=100)\n",
    "    sw_preds = sw.predict_open_loop(test_input)\n",
    "    sw_nrmse = evaluate_nrmse(sw_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SW'].append(sw_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=3,\n",
    "        reservoir_size=400,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=100)\n",
    "    deepesn_preds = deepesn.predict_open_loop(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63e913-1027-4907-b512-59804d9eb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    chord = CHORDESN(\n",
    "        num_nodes         = 400,\n",
    "        input_dim         = 3,\n",
    "        edges             = None,\n",
    "        faces             = None,\n",
    "        avg_degree        = 9,\n",
    "        star0_diag        = None,\n",
    "        star1_diag        = None,\n",
    "        star2_diag        = None,\n",
    "        lam_node          = 0.51,\n",
    "        lam_edge          = 0.33,\n",
    "        lam_face          = 0.69,\n",
    "        leak_exact        = 0.20,\n",
    "        leak_coexact      = 0.20,\n",
    "        leak_harm         = 0.06,\n",
    "        heat0             = 0.06,\n",
    "        heat1             = 0.01,\n",
    "        heat2             = 0.02,\n",
    "        alpha             = 0.41,\n",
    "        beta              = 0.22,\n",
    "        gamma             = 0.37,\n",
    "        node_mix_gain     = 0.67,\n",
    "        edge_mix_gain     = 0.45,\n",
    "        face_mix_gain     = 0.44,\n",
    "        input_scale_node  = 0.15,\n",
    "        input_scale_edge  = 0.21,\n",
    "        input_scale_face  = 0.12,\n",
    "        projector_eps     = 0.000615,\n",
    "        cg_tol            = 0.000624,\n",
    "        cg_maxiter        = 100,\n",
    "        proj_every        = 1,\n",
    "        ridge_alpha       = 0.000008,\n",
    "        use_poly          = True,\n",
    "        feature_mode      = \"node_harm\",\n",
    "        seed              = seed,\n",
    "    )\n",
    "    chord.fit_readout(train_input, train_target, discard=100)\n",
    "    chord_preds = chord.predict_open_loop(test_input)\n",
    "    chord_nrmse = evaluate_nrmse(chord_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CHORD'].append(chord_nrmse)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d186a-3eed-4713-a472-7d5c65a69ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'SW':<17} {'DeepESN':<17} {'CHORD':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    sw_vals = [np.mean(sw_nrmse[horizon]) for sw_nrmse in nrmse_dict['SW']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    chord_vals = [np.mean(chord_nrmse[horizon]) for chord_nrmse in nrmse_dict['CHORD']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, sw_vals, deep_vals, chord_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea3c272-130e-475e-9ec1-94c80d8dafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "VPT_dict = defaultdict(list)\n",
    "VPT_ratio_dict = defaultdict(list)\n",
    "adev_dict = defaultdict(list)\n",
    "\n",
    "all_horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161558e3-addb-4848-be83-b9894123853b",
   "metadata": {},
   "source": [
    "## Santa Fe B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a277f9-19b1-4b14-aac9-8117328c706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = Path(\"..\") / \"datasets\" / \"santa-fe-time-series\" / \"b1.txt\"\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, sep=' ')\n",
    "df\n",
    "# Normalize the first column (column 0) of the DataFrame\n",
    "df[0] = (df[0] - df[0].min()) / (df[0].max() - df[0].min())\n",
    "data = df.iloc[:, 0].values\n",
    "chosen_system = \"SantaFe\"\n",
    "dt = 1\n",
    "T_data = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Data length: {T_data}.\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 7000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}  \\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ce056-91c6-42df-939d-ec3e9550f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "VPT_dict = defaultdict(list)\n",
    "VPT_ratio_dict = defaultdict(list)\n",
    "adev_dict = defaultdict(list)\n",
    "\n",
    "all_horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1000)\n",
    "\n",
    "for seed in seeds:\n",
    "    esn = SparseESN3D(\n",
    "        reservoir_size=300, spectral_radius=0.95, connectivity=0.05,\n",
    "        input_scale=0.2, leaking_rate=0.2,\n",
    "        ridge_alpha=1e-4, seed=seed)\n",
    "    esn.fit_readout(train_input, train_target, discard=100)\n",
    "    esn_preds = esn.predict_open_loop(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=400,\n",
    "        #cycle_weight = 0.8,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=100)\n",
    "    cycle_res_preds = cycle_res.predict_open_loop(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=400,\n",
    "        edge_weight=0.8,\n",
    "        jump=15,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=100)\n",
    "    crj_preds = crj.predict_open_loop(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "for seed in seeds:\n",
    "    sw = SWRes3D_IO(\n",
    "        reservoir_size=400, rewiring_prob=0.10, degree=6,\n",
    "        spectral_radius=0.99, gain=1.30, input_scale=0.20,\n",
    "        leaking_rate=0.20, ridge_alpha=1e-6,\n",
    "        num_input_nodes=12, num_output_nodes=12,\n",
    "        io_separation_mode=\"max\", seed=seed)\n",
    "    \n",
    "    sw.fit_readout(train_input, train_target, discard=100)\n",
    "    sw_preds = sw.predict_open_loop(test_input)\n",
    "    sw_nrmse = evaluate_nrmse(sw_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SW'].append(sw_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=3,\n",
    "        reservoir_size=100,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=100)\n",
    "    deepesn_preds = deepesn.predict_open_loop(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bd9a9-6178-4be0-b262-eb8f690309e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    chord = CHORDESN(\n",
    "        num_nodes         = 400,\n",
    "        input_dim         = 3,\n",
    "        edges             = None,\n",
    "        faces             = None,\n",
    "        avg_degree        = 9,\n",
    "        star0_diag        = None,\n",
    "        star1_diag        = None,\n",
    "        star2_diag        = None,\n",
    "        lam_node          = 0.25,\n",
    "        lam_edge          = 0.25,\n",
    "        lam_face          = 0.25,\n",
    "        leak_exact        = 0.80,\n",
    "        leak_coexact      = 0.80,\n",
    "        leak_harm         = 0.06,\n",
    "        heat0             = 0.05,\n",
    "        heat1             = 0.05,\n",
    "        heat2             = 0.05,\n",
    "        alpha             = 0.31,\n",
    "        beta              = 0.62,\n",
    "        gamma             = 0.07,\n",
    "        node_mix_gain     = 0.30,\n",
    "        edge_mix_gain     = 0.30,\n",
    "        face_mix_gain     = 0.30,\n",
    "        input_scale_node  = 0.50,\n",
    "        input_scale_edge  = 0.50,\n",
    "        input_scale_face  = 0.50,\n",
    "        projector_eps     = 1e-4,\n",
    "        cg_tol            = 1e-6,\n",
    "        cg_maxiter        = 200,\n",
    "        proj_every        = 5,\n",
    "        ridge_alpha       = 1e-6,\n",
    "        use_poly          = False,\n",
    "        feature_mode      = \"full\",\n",
    "        seed              = seed,\n",
    "    )\n",
    "    chord.fit_readout(train_input, train_target, discard=100)\n",
    "    chord_preds = chord.predict_open_loop(test_input)\n",
    "    chord_nrmse = evaluate_nrmse(chord_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CHORD'].append(chord_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88799cc-633d-464f-897c-ade5dee9a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'SW':<17} {'DeepESN':<17} {'CHORD':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    sw_vals = [np.mean(sw_nrmse[horizon]) for sw_nrmse in nrmse_dict['SW']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    chord_vals = [np.mean(chord_nrmse[horizon]) for chord_nrmse in nrmse_dict['CHORD']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, sw_vals, deep_vals, chord_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33b311-9197-4eb0-9190-a3f4e95a31c3",
   "metadata": {},
   "source": [
    "## BIDMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c06cf1b-e34d-4035-8be8-a1c0b1c6a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Load BIDMC Record ─────────────────────────────────────────────────────\n",
    "record_id = 'bidmc01'\n",
    "record = wfdb.rdrecord(record_id, pn_dir='bidmc', sampto=8 * 60 * 125)  # 8 mins at 125Hz\n",
    "signals = record.p_signal  # shape: (60000, 5)\n",
    "names = [n.strip().strip(',') for n in record.sig_name]\n",
    "# ─── Get Indices of ECG Lead II and RESP ──────────────────────────────────\n",
    "idx_ecg = names.index('II')     # ECG Lead II\n",
    "idx_resp = names.index('RESP')  # Respiration signal\n",
    "# ─── Parameters ────────────────────────────────────────────────────────────\n",
    "N_train = 10000\n",
    "N_test = 5000\n",
    "emb_dim = 3\n",
    "# ─── Select Signals ────────────────────────────────────────────────────────\n",
    "u = signals[:, idx_ecg]   # input: ECG Lead II\n",
    "v = signals[:, idx_resp]  # target: RESP\n",
    "# ─── Normalize to [-1, 1] ──────────────────────────────────────────────────\n",
    "u_norm = 2 * (u - np.min(u)) / (np.max(u) - np.min(u)) - 1\n",
    "v_norm = 2 * (v - np.min(v)) / (np.max(v) - np.min(v)) - 1\n",
    "# ─── Delay Embedding ───────────────────────────────────────────────────────\n",
    "inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "targets = create_delay_embedding(v_norm, emb_dim)\n",
    "# ─── Train/Test Split ──────────────────────────────────────────────────────\n",
    "train_input = inputs[:N_train]\n",
    "train_target = targets[:N_train]\n",
    "test_input = inputs[N_train:N_train+N_test]\n",
    "test_target = targets[N_train:N_train+N_test]\n",
    "# ─── Summary ───────────────────────────────────────────────────────────────\n",
    "print(f\"Train input shape:  {train_input.shape}\")\n",
    "print(f\"Train target shape: {train_target.shape}\")\n",
    "print(f\"Test input shape:   {test_input.shape}\")\n",
    "print(f\"Test target shape:  {test_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7fed9-1554-4b06-84fe-9ff3292af0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "VPT_dict = defaultdict(list)\n",
    "VPT_ratio_dict = defaultdict(list)\n",
    "adev_dict = defaultdict(list)\n",
    "\n",
    "all_horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1010)\n",
    "\n",
    "for seed in seeds:\n",
    "    esn = SparseESN3D(\n",
    "        reservoir_size=400, spectral_radius=0.95, connectivity=0.05,\n",
    "        input_scale=0.2, leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6, seed=seed)\n",
    "    esn.fit_readout(train_input, train_target, discard=100)\n",
    "    esn_preds = esn.predict_open_loop(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=400,\n",
    "        #cycle_weight = 0.8,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=100)\n",
    "    cycle_res_preds = cycle_res.predict_open_loop(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=400,\n",
    "        edge_weight=0.8,\n",
    "        jump=15,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=100)\n",
    "    crj_preds = crj.predict_open_loop(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "for seed in seeds:\n",
    "    sw = SWRes3D_IO(\n",
    "        reservoir_size=400, rewiring_prob=0.10, degree=6,\n",
    "        spectral_radius=0.99, gain=1.30, input_scale=0.20,\n",
    "        leaking_rate=0.20, ridge_alpha=1e-6,\n",
    "        num_input_nodes=12, num_output_nodes=12,\n",
    "        io_separation_mode=\"max\", seed=seed)\n",
    "    \n",
    "    sw.fit_readout(train_input, train_target, discard=100)\n",
    "    sw_preds = sw.predict_open_loop(test_input)\n",
    "    sw_nrmse = evaluate_nrmse(sw_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SW'].append(sw_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=3,\n",
    "        reservoir_size=134,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.2,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=100)\n",
    "    deepesn_preds = deepesn.predict_open_loop(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68903094-665f-4bf9-bfa0-017698d5c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in seeds:\n",
    "    chord = CHORDESN(\n",
    "        num_nodes         = 134,\n",
    "        input_dim         = 3,\n",
    "        edges             = None,\n",
    "        faces             = None,\n",
    "        avg_degree        = 5,\n",
    "        star0_diag        = None,\n",
    "        star1_diag        = None,\n",
    "        star2_diag        = None,\n",
    "        lam_node          = 0.47,\n",
    "        lam_edge          = 0.51,\n",
    "        lam_face          = 0.36,\n",
    "        leak_exact        = 0.80,\n",
    "        leak_coexact      = 0.80,\n",
    "        leak_harm         = 0.06,\n",
    "        heat0             = 0.02,\n",
    "        heat1             = 0.02,\n",
    "        heat2             = 0.01,\n",
    "        alpha             = 0.42,\n",
    "        beta              = 0.45,\n",
    "        gamma             = 0.12,\n",
    "        node_mix_gain     = 0.53,\n",
    "        edge_mix_gain     = 0.38,\n",
    "        face_mix_gain     = 0.66,\n",
    "        input_scale_node  = 0.50,\n",
    "        input_scale_edge  = 0.50,\n",
    "        input_scale_face  = 0.50,\n",
    "        projector_eps     = 1e-4,\n",
    "        cg_tol            = 1e-6,\n",
    "        cg_maxiter        = 150,\n",
    "        proj_every        = 2,\n",
    "         ridge_alpha       = 1e-6,\n",
    "        use_poly          = True,\n",
    "        feature_mode      = \"full\",\n",
    "        seed              = seed,\n",
    "    )\n",
    "    chord.fit_readout(train_input, train_target, discard=100)\n",
    "    chord_preds = chord.predict_open_loop(test_input)\n",
    "    chord_nrmse = evaluate_nrmse(chord_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CHORD'].append(chord_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52410032-ed73-476a-acbb-0762441c73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'SW':<17} {'DeepESN':<17} {'CHORD':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    sw_vals = [np.mean(sw_nrmse[horizon]) for sw_nrmse in nrmse_dict['SW']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    chord_vals = [np.mean(chord_nrmse[horizon]) for chord_nrmse in nrmse_dict['CHORD']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, sw_vals, deep_vals, chord_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8878c9b9-0e98-423e-a7fc-b4a897cb9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Statistical significance on NRMSE ====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "\n",
    "# ---- helpers ---------------------------------------------------------------\n",
    "def _to_scalar(x):\n",
    "    \"\"\"Robustly turn evaluate_nrmse() output (scalar/array) into scalar.\"\"\"\n",
    "    x = np.asarray(x).astype(float)\n",
    "    return float(np.nanmean(x))\n",
    "\n",
    "def make_score_matrix(nrmse_dict, horizon):\n",
    "    \"\"\"\n",
    "    Returns models(list), scores(array shape [R, M]) where R = paired runs (seeds)\n",
    "    paired by index order (same seeds order used for every model).\n",
    "    Drops models with empty runs.\n",
    "    \"\"\"\n",
    "    models = [m for m in nrmse_dict.keys() if len(nrmse_dict[m]) > 0]\n",
    "    if not models:\n",
    "        raise RuntimeError(\"nrmse_dict is empty.\")\n",
    "    # number of paired trials = min number of runs across models\n",
    "    R = min(len(nrmse_dict[m]) for m in models)\n",
    "    if R < 2:\n",
    "        raise RuntimeError(\"Need at least 2 paired runs per model for significance tests.\")\n",
    "    # build R x M\n",
    "    M = len(models)\n",
    "    S = np.empty((R, M), dtype=float)\n",
    "    for j, m in enumerate(models):\n",
    "        for i in range(R):\n",
    "            S[i, j] = _to_scalar(nrmse_dict[m][i][horizon])\n",
    "    return models, S\n",
    "\n",
    "def average_ranks(scores):\n",
    "    \"\"\"Average ranks across columns (models), lower score = better (rank 1).\"\"\"\n",
    "    # rank per row\n",
    "    ranks = np.argsort(np.argsort(scores, axis=1), axis=1).astype(float) + 1.0\n",
    "    # Convert to *dense ranks* for ties: use scipy rankdata with method='average'\n",
    "    from scipy.stats import rankdata\n",
    "    dense = np.vstack([rankdata(row, method='average') for row in scores])\n",
    "    return dense.mean(axis=0)\n",
    "\n",
    "def holm_bonferroni(pvals, labels):\n",
    "    \"\"\"\n",
    "    Return DataFrame with Holm–Bonferroni adjusted p-values for a dict {label: p}.\n",
    "    \"\"\"\n",
    "    items = sorted([(lab, float(p)) for lab, p in pvals.items()], key=lambda x: x[1])\n",
    "    m = len(items)\n",
    "    adj = {}\n",
    "    running_max = 0.0\n",
    "    for i, (lab, p) in enumerate(items, start=1):\n",
    "        adj_p = min(1.0, (m - i + 1) * p)\n",
    "        running_max = max(running_max, adj_p)\n",
    "        adj[lab] = running_max\n",
    "    # restore original order\n",
    "    return pd.DataFrame(\n",
    "        [{\"Comparison\": lab, \"p_raw\": p, \"p_holm\": adj[lab]} for lab, p in pvals.items()]\n",
    "    ).sort_values(\"p_raw\")\n",
    "\n",
    "def paired_effects(x, y):\n",
    "    \"\"\"\n",
    "    Paired effects for (x,y): returns dict with mean_diff, t_paired, p_ttest,\n",
    "    cohen_d (paired), wilcoxon_p.\n",
    "    \"\"\"\n",
    "    d = y - x  # improvement if negative (since NRMSE lower is better)\n",
    "    mean_diff = float(np.mean(d))\n",
    "    # paired t-test\n",
    "    t_stat, p_t = stats.ttest_rel(y, x, nan_policy='omit')  # test y vs x\n",
    "    # Cohen's d for paired samples\n",
    "    sd = np.std(d, ddof=1)\n",
    "    cohen_d = float(mean_diff / sd) if sd > 0 else np.nan\n",
    "    # Wilcoxon signed-rank (non-param), include zeros (Pratt)\n",
    "    try:\n",
    "        w = stats.wilcoxon(y, x, zero_method='pratt', alternative='two-sided')\n",
    "        p_w = float(w.pvalue)\n",
    "    except Exception:\n",
    "        p_w = np.nan\n",
    "    return dict(mean_diff=mean_diff, t=t_stat, p_ttest=p_t, d=cohen_d, p_wilcoxon=p_w)\n",
    "\n",
    "def print_header(h, models, R):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Horizon = {h} | models = {len(models)} | paired runs (seeds) = {R}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "def critical_difference(k, N, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Demsar CD for average ranks (approx, q_alpha=2.728 at alpha=0.05).\n",
    "    \"\"\"\n",
    "    q_alpha = 2.728  # two-tailed, large sample approx\n",
    "    return q_alpha * np.sqrt(k*(k+1) / (6.0*N))\n",
    "\n",
    "# ---- main loop over horizons ----------------------------------------------\n",
    "all_results = {}\n",
    "for h in all_horizons:\n",
    "    models, S = make_score_matrix(nrmse_dict, horizon=h)   # S shape [R, M]\n",
    "    R, M = S.shape\n",
    "    print_header(h, models, R)\n",
    "\n",
    "    # Descriptives\n",
    "    desc = pd.DataFrame({\n",
    "        \"Model\": models,\n",
    "        \"Mean\":  S.mean(axis=0),\n",
    "        \"SD\":    S.std(axis=0, ddof=1)\n",
    "    }).sort_values(\"Mean\")\n",
    "    print(\"\\nDescriptives (lower is better):\")\n",
    "    print(desc.to_string(index=False, float_format=lambda x: f\"{x:.5f}\"))\n",
    "\n",
    "    # Friedman omnibus\n",
    "    # scipy expects each condition as a 1D array of length R\n",
    "    fried = stats.friedmanchisquare(*[S[:, j] for j in range(M)])\n",
    "    print(f\"\\nFriedman test: χ²({M-1}) = {fried.statistic:.3f}, p = {fried.pvalue:.6g}\")\n",
    "\n",
    "    # Average ranks + CD\n",
    "    ranks = average_ranks(S)  # mean rank per model\n",
    "    cd = critical_difference(M, R, alpha=0.05)\n",
    "    rank_df = pd.DataFrame({\"Model\": models, \"AvgRank\": ranks}).sort_values(\"AvgRank\")\n",
    "    print(\"\\nAverage ranks (lower = better). Critical Difference (α=0.05): \"\n",
    "          f\"CD ≈ {cd:.3f}\")\n",
    "    print(rank_df.to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))\n",
    "\n",
    "    # Pairwise comparisons (paired)\n",
    "    pw_rows = []\n",
    "    pvals = {}\n",
    "    for (i, j) in combinations(range(M), 2):\n",
    "        m_i, m_j = models[i], models[j]\n",
    "        eff = paired_effects(S[:, i], S[:, j])\n",
    "        # store raw p (Wilcoxon) for Holm\n",
    "        p_label = f\"{m_i} vs {m_j}\"\n",
    "        pvals[p_label] = eff[\"p_wilcoxon\"]\n",
    "        pw_rows.append({\n",
    "            \"A\": m_i, \"B\": m_j,\n",
    "            \"Δ(B−A)\": eff[\"mean_diff\"],   # negative => B better than A on average\n",
    "            \"Cohen_d\": eff[\"d\"],\n",
    "            \"p_wilcoxon\": eff[\"p_wilcoxon\"],\n",
    "            \"p_ttest\": eff[\"p_ttest\"]\n",
    "        })\n",
    "    pw_df = pd.DataFrame(pw_rows).sort_values(\"p_wilcoxon\")\n",
    "    holm_df = holm_bonferroni(pvals, labels=list(pvals.keys()))\n",
    "    pw_df = pw_df.merge(holm_df, left_on=pw_df.apply(lambda r: f\"{r['A']} vs {r['B']}\", axis=1),\n",
    "                        right_on=\"Comparison\", how=\"left\").drop(columns=[\"Comparison\"])\n",
    "    # pretty print\n",
    "    print(\"\\nPairwise (paired) – Wilcoxon p (Holm-adj) and Cohen’s d (paired):\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.width', 140):\n",
    "        print(pw_df[[\"A\",\"B\",\"Δ(B−A)\",\"Cohen_d\",\"p_wilcoxon\",\"p_holm\",\"p_ttest\"]]\n",
    "              .to_string(index=False, float_format=lambda x: f\"{x:.5g}\"))\n",
    "\n",
    "    # stash results\n",
    "    all_results[h] = dict(descriptives=desc, ranks=rank_df, pairwise=pw_df,\n",
    "                          friedman=dict(stat=fried.statistic, p=fried.pvalue, dof=M-1), CD=cd)\n",
    "\n",
    "# ---- pick a primary horizon and save CSVs ------------------------\n",
    "PRIMARY = 1000 if 1000 in all_results else all_horizons[-1]\n",
    "res = all_results[PRIMARY]\n",
    "res[\"descriptives\"].to_csv(f\"stats_desc_h{PRIMARY}.csv\", index=False)\n",
    "res[\"ranks\"].to_csv(f\"stats_ranks_h{PRIMARY}.csv\", index=False)\n",
    "res[\"pairwise\"].to_csv(f\"stats_pairwise_h{PRIMARY}.csv\", index=False)\n",
    "\n",
    "print(f\"\\nSaved CSVs for horizon={PRIMARY}: stats_desc_h{PRIMARY}.csv, \"\n",
    "      f\"stats_ranks_h{PRIMARY}.csv, stats_pairwise_h{PRIMARY}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1185a781-72cb-4428-a2a2-e907d6f0361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= NRMSE boxplots by horizon (from nrmse_dict) =======================\n",
    "\n",
    "# ---- 1) Build a long DataFrame: Model × Horizon × NRMSE (across seeds/runs)\n",
    "rows = []\n",
    "for model, runs in nrmse_dict.items():\n",
    "    # each 'runs[i]' is typically a dict {horizon -> nrmse}\n",
    "    for run_idx, res in enumerate(runs):\n",
    "        if isinstance(res, dict):\n",
    "            for h, v in res.items():\n",
    "                rows.append({\"Model\": model, \"Horizon\": int(h), \"NRMSE\": float(v), \"Run\": run_idx})\n",
    "        else:\n",
    "            # fallback: assume it's aligned with all_horizons list\n",
    "            for h, v in zip(all_horizons, res):\n",
    "                rows.append({\"Model\": model, \"Horizon\": int(h), \"NRMSE\": float(v), \"Run\": run_idx})\n",
    "\n",
    "df_nrmse_h = pd.DataFrame(rows)\n",
    "df_nrmse_h = df_nrmse_h.dropna(subset=[\"NRMSE\"])\n",
    "df_nrmse_h[\"Horizon\"] = df_nrmse_h[\"Horizon\"].astype(int)\n",
    "df_nrmse_h = df_nrmse_h.sort_values([\"Horizon\", \"Model\"]).reset_index(drop=True)\n",
    "\n",
    "# ---- 2) Plot manual grouped boxplot with small separation between models\n",
    "SYSTEM  = globals().get(\"SYSTEM\", \"signal\")\n",
    "FIG_DIR = globals().get(\"FIG_DIR\", Path(\"figs\"))\n",
    "\n",
    "#horizons = sorted(df_nrmse_h[\"Horizon\"].unique())\n",
    "horizons = [1000]\n",
    "models   = sorted(df_nrmse_h[\"Model\"].unique())\n",
    "palette  = sns.color_palette(\"tab10\", n_colors=len(models))\n",
    "color_of = {m: palette[i] for i, m in enumerate(models)}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10.8, 4.6))\n",
    "\n",
    "centers     = np.arange(len(horizons))          # one group per horizon\n",
    "group_width = 0.82                               # total width reserved for a group\n",
    "inner_gap   = 0.06                               # gap between adjacent model boxes\n",
    "M           = max(1, len(models))\n",
    "box_w       = (group_width - inner_gap*(M-1)) / M\n",
    "start_off   = -group_width/2 + box_w/2\n",
    "offsets     = start_off + np.arange(M) * (box_w + inner_gap)\n",
    "\n",
    "# Collect data & positions for matplotlib.boxplot\n",
    "all_data, positions, colors = [], [], []\n",
    "for gi, h in enumerate(horizons):\n",
    "    center = centers[gi]\n",
    "    for mi, m in enumerate(models):\n",
    "        vals = df_nrmse_h.query(\"Horizon == @h and Model == @m\")[\"NRMSE\"].values\n",
    "        if vals.size == 0:\n",
    "            continue\n",
    "        all_data.append(vals)\n",
    "        positions.append(center + offsets[mi])\n",
    "        colors.append(color_of[m])\n",
    "\n",
    "bp = ax.boxplot(\n",
    "    all_data,\n",
    "    positions=positions,\n",
    "    widths=box_w * 0.95,\n",
    "    patch_artist=True,\n",
    "    showfliers=False,\n",
    "    showcaps=True,\n",
    "    medianprops=dict(color=\"#1a1a1a\", linewidth=1.6),\n",
    "    whiskerprops=dict(color=\"#555\", linewidth=1.2),\n",
    "    capprops=dict(color=\"#555\", linewidth=1.2)\n",
    ")\n",
    "\n",
    "# Color each box\n",
    "for patch, c in zip(bp[\"boxes\"], colors):\n",
    "    patch.set_facecolor(c)\n",
    "    patch.set_edgecolor(\"#2b2b2b\")\n",
    "    patch.set_alpha(0.8)\n",
    "    patch.set_linewidth(1.0)\n",
    "\n",
    "# Ticks & labels\n",
    "ax.set_xticks(centers)\n",
    "ax.set_xticklabels([str(h) for h in horizons])\n",
    "ax.set_xlim(centers[0] - 0.6, centers[-1] + 0.6)\n",
    "\n",
    "# Light separators between horizon groups (optional)\n",
    "for g in centers[:-1]:\n",
    "    ax.axvline(g + 0.5, color=\"#e8e8e8\", lw=0.6, zorder=0)\n",
    "\n",
    "# Legend\n",
    "handles = [Patch(facecolor=color_of[m], edgecolor=\"#2b2b2b\", label=m, alpha=0.8) for m in models]\n",
    "ax.legend(handles=handles, title=\"Model\", ncol=3, frameon=False)\n",
    "\n",
    "ax.set_ylabel(\"NRMSE\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_title(f\"{SYSTEM.title()}: NRMSE distribution by horizon\")\n",
    "ax.grid(axis=\"y\", alpha=0.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "out_path = FIG_DIR / f\"{SYSTEM}_box_nrmse_by_horizon.png\"\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8db302-2d2b-46dc-95ba-fd642c563ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(horizons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acff4e-a3a3-4b77-ab6b-e1db075ee10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Horizon curves with mean ± 95% CI ribbons (per model)\n",
    "# ============================================================\n",
    "\n",
    "# mean & CI per model × horizon\n",
    "agg = (df_nrmse_h\n",
    "       .groupby([\"Model\",\"Horizon\"])[\"NRMSE\"]\n",
    "       .agg([\"mean\",\"std\",\"count\"])\n",
    "       .reset_index())\n",
    "agg[\"se\"] = agg[\"std\"] / np.sqrt(agg[\"count\"].clip(lower=1))\n",
    "agg[\"lo\"] = agg[\"mean\"] - 1.96 * agg[\"se\"]\n",
    "agg[\"hi\"] = agg[\"mean\"] + 1.96 * agg[\"se\"]\n",
    "\n",
    "plt.figure(figsize=(8.8, 5))\n",
    "for m, sub in agg.groupby(\"Model\"):\n",
    "    sub = sub.sort_values(\"Horizon\")\n",
    "    plt.plot(sub[\"Horizon\"], sub[\"mean\"], label=m, linewidth=2)\n",
    "    plt.fill_between(sub[\"Horizon\"], sub[\"lo\"], sub[\"hi\"], alpha=0.18)\n",
    "\n",
    "plt.xlabel(\"Horizon\"); plt.ylabel(\"NRMSE (mean ± 95% CI)\")\n",
    "plt.title(f\"{SYSTEM.title()}: Horizon-wise performance with uncertainty\")\n",
    "plt.legend(frameon=False, ncol=2)\n",
    "plt.grid(alpha=0.25)\n",
    "plt.tight_layout()\n",
    "out = FIG_DIR / f\"{SYSTEM}_horizon_ribbons.png\"\n",
    "plt.savefig(out, dpi=300, bbox_inches=\"tight\"); plt.show()\n",
    "print(f\"Saved: {out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5b4ef-7f73-402b-8451-2f8ca2303057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
